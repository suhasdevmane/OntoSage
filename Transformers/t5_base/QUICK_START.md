# Quick Start: Fix Your NL2SPARQL Model

## âœ… What We Just Did

1. **Added 5 Correlation Training Examples** to your T5 model dataset
   - Your exact question with 6 sensors
   - 4 additional variations with 2-4 sensors each
   - Total examples: **24,420 â†’ 24,425**

2. **Created Backup**
   - Location: `training/backups/bldg1_dataset_backup_20251007_232753.json`

3. **Created Training Tools**
   - `train_t5_model.py` - Full training script with GPU support
   - `add_training_example.py` - Easy way to add more examples
   - `TRAINING_GUIDE.md` - Complete documentation

## ğŸš€ Next Step: Retrain the Model

### Option 1: Quick Retrain (Recommended First)
```powershell
cd c:\Users\suhas\Documents\GitHub\OntoBot\Transformers\t5_base
python train_t5_model.py --epochs 3 --batch-size 4
```

**Time:** ~1-2 hours on CPU, ~10-20 min on GPU  
**Result:** New model in `trained/checkpoint-final/`

### Option 2: Fast Retrain (Smaller Model)
```powershell
python train_t5_model.py --base-model t5-small --epochs 3 --batch-size 8
```

**Time:** ~30-60 min on CPU, ~5-10 min on GPU  
**Result:** Faster but slightly less accurate

### Option 3: Thorough Retrain (More Epochs)
```powershell
python train_t5_model.py --epochs 5 --batch-size 4 --learning-rate 3e-5
```

**Time:** ~2-3 hours on CPU, ~20-30 min on GPU  
**Result:** Better accuracy, more training time

## ğŸ“¦ Deploy the New Model

After training completes:

```powershell
# Navigate back to project root
cd c:\Users\suhas\Documents\GitHub\OntoBot

# Copy trained model to production location
Copy-Item -Path "Transformers\t5_base\trained\checkpoint-final" -Destination "Transformers\t5_base\trained\checkpoint-3" -Recurse -Force

# Restart the NL2SPARQL service
docker-compose -f docker-compose.bldg1.yml restart nl2sparql
```

## ğŸ§ª Test It

Ask your question again:
> "What is the correlation between Zone_Air_Humidity_Sensor_5.04, CO_Level_Sensor_5.04, PM10_Level_Sensor_Atmospheric_5.04, NO2_Level_Sensor_5.04, CO2_Level_Sensor_5.04, PM2.5_Level_Sensor_Atmospheric_5.04 sensors readings and the overall building air quality index based on the dates 01/02/2025 to 05/02/2025?"

**Expected Output:**
```sparql
SELECT ?sensor ?timeseriesId ?storedAt WHERE {
    VALUES ?sensor {
        bldg:Zone_Air_Humidity_Sensor_5.04
        bldg:CO_Level_Sensor_5.04
        bldg:PM10_Level_Sensor_Atmospheric_5.04
        bldg:NO2_Level_Sensor_5.04
        bldg:CO2_Level_Sensor_5.04
        bldg:PM2.5_Level_Sensor_Atmospheric_5.04
    }
    ?sensor ref:hasExternalReference ?ref .
    ?ref a ref:TimeseriesReference ;
         ref:hasTimeseriesId ?timeseriesId ;
         ref:storedAt ?storedAt .
}
```

## ğŸ“ Adding More Examples in the Future

### Method 1: Edit JSON Directly
Open: `Transformers/t5_base/training/bldg1/bldg1_dataset_extended.json`

Add before the closing `]`:
```json
{
  "question": "Your new question",
  "entities": ["bldg:Sensor1", "bldg:Sensor2"],
  "sparql": "SELECT ... WHERE { ... }",
  "category": "correlation",
  "notes": "Optional note"
}
```

### Method 2: Use the Script
Edit: `training/add_training_example.py`

Add to `add_correlation_example()`:
```python
examples.append({
    "question": "Your new question",
    "entities": ["bldg:Sensor1"],
    "sparql": "SELECT ... WHERE { ... }",
    "category": "my_category"
})
```

Run:
```powershell
python training/add_training_example.py
python train_t5_model.py
```

## ğŸ¯ Training Tips

1. **Add 5-10 examples per pattern** for best results
2. **Include variations** with different numbers of sensors (2, 3, 4, 6 sensors)
3. **Test after each retrain** before deploying
4. **Keep backups** - they're auto-generated in `training/backups/`
5. **Monitor training** - watch the eval_loss metric

## ğŸ“Š What Changed?

| Metric | Before | After |
|--------|--------|-------|
| Training Examples | 24,420 | 24,425 |
| Multi-Sensor Queries | âŒ Poor | âœ… Good (after retraining) |
| Backup Created | - | âœ… Yes |

## ğŸ” Files Created

```
Transformers/t5_base/
â”œâ”€â”€ train_t5_model.py           # Main training script
â”œâ”€â”€ TRAINING_GUIDE.md            # Full documentation
â”œâ”€â”€ QUICK_START.md               # This file
â””â”€â”€ training/
    â”œâ”€â”€ add_training_example.py  # Example addition script
    â”œâ”€â”€ backups/
    â”‚   â””â”€â”€ bldg1_dataset_backup_20251007_232753.json
    â””â”€â”€ bldg1/
        â””â”€â”€ bldg1_dataset_extended.json  # Updated with 5 new examples
```

## â“ Troubleshooting

### Out of Memory Error
Reduce batch size:
```powershell
python train_t5_model.py --batch-size 2
```

### Training Too Slow
Use smaller model:
```powershell
python train_t5_model.py --base-model t5-small
```

### Model Not Improving
Add more examples and increase epochs:
```powershell
# Add 10-20 more examples, then:
python train_t5_model.py --epochs 5
```

---

## ğŸ‰ Summary

**What's Done:**
- âœ… Added 5 multi-sensor correlation examples
- âœ… Created backup of original dataset  
- âœ… Built training infrastructure
- âœ… Documented everything

**What's Next:**
1. â³ Run training (1-2 hours)
2. ğŸš€ Deploy new model
3. âœ… Test with your question
4. ğŸ¯ Add more examples as needed

**Ready to train?**
```powershell
cd c:\Users\suhas\Documents\GitHub\OntoBot\Transformers\t5_base
python train_t5_model.py
```

---

**Need help?** Check `TRAINING_GUIDE.md` for detailed instructions.
