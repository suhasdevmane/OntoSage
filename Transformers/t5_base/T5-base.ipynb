{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install / upgrade core dependencies (safe to re-run). Comment out versions to use latest.\n",
    "%pip install \\\n",
    "  transformers==4.44.2 \\\n",
    "  datasets==2.21.0 \\\n",
    "  evaluate==0.4.2 \\\n",
    "  accelerate==0.34.2 \\\n",
    "  sentencepiece==0.2.0 \\\n",
    "  nltk==3.9.1 \\\n",
    "  rouge-score==0.1.2 \\\n",
    "  bert-score==0.3.13 \\\n",
    "  sacrebleu==2.4.3 \\\n",
    "  scikit-learn==1.5.2 \\\n",
    "  pandas==2.2.2 \\\n",
    "  numpy==1.26.4 \\\n",
    "  torch --upgrade --quiet\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True)\n",
    "print('Dependencies installed and punkt tokenizer downloaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment & Dependencies\n",
    "\n",
    "Run the next cell once per environment to ensure all required packages (with tested versions) are installed before training/fine-tuning.\n",
    "\n",
    "Core libraries:\n",
    "- transformers (seq2seq model + trainer)\n",
    "- datasets (dataset handling)\n",
    "- evaluate (metrics hub)\n",
    "- accelerate (efficient distributed / mixed precision)\n",
    "- sentencepiece (tokenization backend for T5)\n",
    "- nltk (optional: sentence tokenization, metrics)\n",
    "- rouge_score, bert_score, sacrebleu (evaluation)\n",
    "- scikit-learn (train/validation split)\n",
    "- numpy, pandas (general utilities)\n",
    "\n",
    "Pin versions if you need reproducibility; here we choose recent stable versions that work well with T5-base. Adjust as needed for CUDA / platform constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "def clear_cuda_cache():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"CUDA cache cleared and memory freed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 01:25:46.548464: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-06 01:25:46.565218: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743902746.585703    7321 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743902746.591963    7321 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-06 01:25:46.613267: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    T5Tokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    DataCollatorForSeq2Seq,\n",
    ")\n",
    "import nltk\n",
    "from typing import List, Tuple\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import T5Tokenizer, DataCollatorForSeq2Seq\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\suhas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.34.2)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-1.10.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\suhas\\appdata\\roaming\\python\\python310\\site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\suhas\\appdata\\roaming\\python\\python310\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\suhas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from accelerate) (2.8.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from accelerate) (0.34.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\suhas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2024.6.1)\n",
      "Requirement already satisfied: requests in c:\\users\\suhas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\suhas\\appdata\\roaming\\python\\python310\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\suhas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\suhas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\suhas\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.8.3)\n",
      "Using cached accelerate-1.10.1-py3-none-any.whl (374 kB)\n",
      "Installing collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.34.2\n",
      "    Uninstalling accelerate-0.34.2:\n",
      "      Successfully uninstalled accelerate-0.34.2\n",
      "Successfully installed accelerate-1.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (0.4.3)\n",
      "Requirement already satisfied: nltk in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: rouge_score in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (0.1.2)\n",
      "Requirement already satisfied: bert_score in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (0.3.13)\n",
      "Requirement already satisfied: transformers[torch] in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (4.39.3)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from evaluate) (2.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from evaluate) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from evaluate) (4.66.2)\n",
      "Requirement already satisfied: xxhash in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.3.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from evaluate) (0.22.2)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from evaluate) (23.2)\n",
      "Requirement already satisfied: click in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from nltk) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: absl-py in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from rouge_score) (2.1.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: torch>=1.0.0 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from bert_score) (2.2.2)\n",
      "Requirement already satisfied: matplotlib in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from bert_score) (3.8.4)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from transformers[torch]) (3.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from transformers[torch]) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from transformers[torch]) (0.5.3)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from transformers[torch]) (1.6.0)\n",
      "Requirement already satisfied: psutil in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
      "Requirement already satisfied: sympy in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->bert_score) (12.5.82)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from matplotlib->bert_score) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from matplotlib->bert_score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from matplotlib->bert_score) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from matplotlib->bert_score) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from matplotlib->bert_score) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from matplotlib->bert_score) (3.1.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ubuntu/anaconda3/envs/tf-gpu/lib/python3.11/site-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install evaluate nltk rouge_score bert_score transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data preparation and making decisions for additional tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁brick', ':', 'N', 'atura', 'l', '_', 'G', 'a', 's', '▁', 'r', 'd', 'f', 's', ':', 'l', 'abel', '▁', '?', 'l', 'abel', '▁', 'SEL', 'ECT', '▁W', 'HER', 'E', '▁brick', ':', 'Air', '_', 'Flow', '_', 'S', 'en', 's', 'or']\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    tokenizer.tokenize(\n",
    "        \"brick:Natural_Gas rdfs:label ?label SELECT WHERE brick:Air_Flow_Sensor\"\n",
    "    )\n",
    ")\n",
    "# Output: ['brick', ':', 'Natural', '_', 'Gas', 'rdfs', ':', 'label', '?', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files merged successfully into 'merged_output.json' with keys: 'question', 'entity', and 'sparql'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the first JSON file\n",
    "with open(\"updated_bldg_question_pairs_entities.json\", \"r\") as f1:\n",
    "    data1 = json.load(f1)\n",
    "\n",
    "# Load the second JSON file\n",
    "with open(\"updated_combined_output_with_entity.json\", \"r\") as f2:\n",
    "    data2 = json.load(f2)\n",
    "\n",
    "\n",
    "# Function to filter and extract only the required keys\n",
    "def filter_entry(entry):\n",
    "    return {\n",
    "        \"question\": entry[\"question\"],\n",
    "        \"entity\": entry[\"entity\"],\n",
    "        \"sparql\": entry[\"sparql\"],\n",
    "    }\n",
    "\n",
    "\n",
    "# Process both datasets and combine them\n",
    "merged_data = []\n",
    "\n",
    "# Filter entries from file1.json\n",
    "for entry in data1:\n",
    "    filtered_entry = filter_entry(entry)\n",
    "    merged_data.append(filtered_entry)\n",
    "\n",
    "# Filter entries from file2.json\n",
    "for entry in data2:\n",
    "    filtered_entry = filter_entry(entry)\n",
    "    merged_data.append(filtered_entry)\n",
    "\n",
    "# Save the merged dataset to a new JSON file\n",
    "with open(\"merged_output1.json\", \"w\") as f:\n",
    "    json.dump(merged_data, f, indent=4)\n",
    "\n",
    "print(\n",
    "    \"Files merged successfully into 'merged_output.json' with keys: 'question', 'entity', and 'sparql'.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files merged successfully into 'merged_output.json' with keys: 'question', 'entity', and 'sparql'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the first JSON file\n",
    "with open(\"abacws_bldg_question_pairs_entities.json\", \"r\") as f1:\n",
    "    data1 = json.load(f1)\n",
    "\n",
    "# Load the second JSON file\n",
    "with open(\"abacws_bldg_timeseries_question_pairs_entities.json\", \"r\") as f2:\n",
    "    data2 = json.load(f2)\n",
    "\n",
    "#  # Load the second JSON file\n",
    "# with open(\"updated_bldg_question_pairs_entities.json\", \"r\") as f3:\n",
    "#     data3 = json.load(f3)\n",
    "\n",
    "\n",
    "# Function to filter and extract only the required keys\n",
    "def filter_entry(entry):\n",
    "    return {\n",
    "        \"question\": entry[\"question\"],\n",
    "        \"entity\": entry[\"entity\"],\n",
    "        \"sparql\": entry[\"sparql\"],\n",
    "    }\n",
    "\n",
    "\n",
    "# Process both datasets and combine them\n",
    "merged_data = []\n",
    "\n",
    "# Filter entries from file1.json\n",
    "for entry in data1:\n",
    "    filtered_entry = filter_entry(entry)\n",
    "    merged_data.append(filtered_entry)\n",
    "\n",
    "# Filter entries from file2.json\n",
    "for entry in data2:\n",
    "    filtered_entry = filter_entry(entry)\n",
    "    merged_data.append(filtered_entry)\n",
    "\n",
    "# Filter entries from file2.json\n",
    "# for entry in data3:\n",
    "#     filtered_entry = filter_entry(entry)\n",
    "#     merged_data.append(filtered_entry)\n",
    "\n",
    "# Save the merged dataset to a new JSON file\n",
    "with open(\"merged_output2.json\", \"w\") as f:\n",
    "    json.dump(merged_data, f, indent=4)\n",
    "\n",
    "print(\n",
    "    \"Files merged successfully into 'merged_output.json' with keys: 'question', 'entity', and 'sparql'.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files merged successfully into 'merged_output.json' with keys: 'question', 'entity', and 'sparql'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the first JSON file\n",
    "with open(\"merged_output2.json\", \"r\") as f1:\n",
    "    data1 = json.load(f1)\n",
    "  \n",
    "# Load the second JSON file\n",
    "with open(\"merged_output3.json\", \"r\") as f2:\n",
    "    data2 = json.load(f2)\n",
    "\n",
    "\n",
    "# Function to filter and extract only the required keys\n",
    "def filter_entry(entry):\n",
    "    return {\n",
    "        \"question\": entry[\"question\"],\n",
    "        \"entity\": entry[\"entity\"],\n",
    "        \"sparql\": entry[\"sparql\"],\n",
    "    }\n",
    "\n",
    "\n",
    "# Process both datasets and combine them\n",
    "merged_data = []\n",
    "\n",
    "# Filter entries from file1.json\n",
    "for entry in data1:\n",
    "    filtered_entry = filter_entry(entry)\n",
    "    merged_data.append(filtered_entry)\n",
    "\n",
    "# Filter entries from file2.json\n",
    "for entry in data2:\n",
    "    filtered_entry = filter_entry(entry)\n",
    "    merged_data.append(filtered_entry)\n",
    "\n",
    "# Save the merged dataset to a new JSON file\n",
    "with open(\"training_data.json\", \"w\") as f:\n",
    "    json.dump(merged_data, f, indent=4)\n",
    "\n",
    "print(\n",
    "    \"Files merged successfully into 'merged_output.json' with keys: 'question', 'entity', and 'sparql'.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset generated and saved to 'sparql_dataset1.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "# Function to read names from a file (one per line)\n",
    "def load_names_from_file(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        # Strip whitespace and filter out empty lines\n",
    "        names = [line.strip() for line in f if line.strip()]\n",
    "    return names\n",
    "\n",
    "\n",
    "# Load sensors and zones from files\n",
    "sensors = load_names_from_file(\"brick_sensors.txt\")\n",
    "zones = load_names_from_file(\"bldg_zones.txt\")\n",
    "\n",
    "# Add 'brick:' prefix to sensors and 'bldg:' prefix to zones if not already present\n",
    "sensors = [f\"brick:{s}\" if not s.startswith(\"brick:\") else s for s in sensors]\n",
    "zones = [f\"bldg:{z}\" if not z.startswith(\"bldg:\") else z for z in zones]\n",
    "\n",
    "\n",
    "# Function to generate SPARQL queries and dataset entries\n",
    "def generate_sparql_dataset(sensors_list, zones_list):\n",
    "    dataset = []\n",
    "\n",
    "    # Base entity template (e.g., \"bldg:<Zone> \\n brick:<SensorName>\")\n",
    "    def get_entity(sensor, zone):\n",
    "        sensor_name = sensor.split(\":\")[1]  # Extract sensor name after \"brick:\"\n",
    "        zone_name = zone.split(\":\")[1]  # Extract zone name after \"bldg:\"\n",
    "        return f\"bldg:{zone_name} \\n brick:{sensor_name}\"  # Newline-separated format\n",
    "\n",
    "    # Loop over each sensor and each zone\n",
    "    for sensor in sensors_list:\n",
    "        for zone in zones_list:\n",
    "            selected_entity = get_entity(sensor, zone)\n",
    "\n",
    "            # Create the question string with sensor and zone details\n",
    "            question = (\n",
    "                f\"Tell me the name or label of the {sensor.split(':')[1].replace('_', ' ').lower()} \"\n",
    "                f\"in the {zone.split(':')[1].replace('-', ' ').replace('_', ' ')}.\"\n",
    "            )\n",
    "\n",
    "            # Create the corresponding SPARQL query\n",
    "            sparql_query = f\"SELECT ?label WHERE {{ ?sensor a {sensor} ; brick:hasLocation {zone} ; rdfs:label ?label . }}\"\n",
    "\n",
    "            # Create an entry and append it to the dataset\n",
    "            entry = {\n",
    "                \"question\": question,\n",
    "                \"entity\": selected_entity,\n",
    "                \"sparql\": sparql_query,\n",
    "            }\n",
    "            dataset.append(entry)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Generate the dataset (will produce 5000 entries if there are 100 sensors and 50 zones)\n",
    "dataset = generate_sparql_dataset(sensors, zones)\n",
    "\n",
    "# Save to JSON file\n",
    "with open(\"merged_output3.json\", \"w\") as f:\n",
    "    json.dump(dataset, f, indent=4)\n",
    "\n",
    "print(\"Dataset generated and saved to 'sparql_dataset1.json'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "def clear_cuda_cache():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"CUDA cache cleared and memory freed.\")\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, EarlyStoppingCallback\n",
    "import gc\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "import evaluate\n",
    "import torch\n",
    "import nltk\n",
    "import numpy as np\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, DataCollatorForSeq2Seq\n",
    "\n",
    "# Set CUDA device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "\n",
    "# 1. LOAD AND PREPARE DATA\n",
    "DATA_FILE = \"updated_combined_output_with_entity.json\"\n",
    "with open(DATA_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "print(f\"Loaded {len(data)} records from {DATA_FILE}\")\n",
    "print(\"Example record:\", data[0])\n",
    "\n",
    "# Create multi-task training pairs\n",
    "inputs, targets = [], []\n",
    "for record in data:\n",
    "    question = record.get(\"question\", \"\")\n",
    "    entity = record.get(\"entity\", \"\")\n",
    "    sparql = record.get(\"sparql\", \"\")\n",
    "    # response = record.get(\"sparql_response\", \"\")\n",
    "    # explanation = record.get(\"explanation\", \"\")\n",
    "\n",
    "    # Task 1: NL to SPARQL\n",
    "    if question and entity and sparql:\n",
    "        inputs.append(f\"task: generate_sparql\\ninput: {question}\\nentity{entity}\")\n",
    "        targets.append(sparql)\n",
    "\n",
    "    # # Task 2: Summarize response\n",
    "    # if question and response and explanation:\n",
    "    #     inputs.append(f\"task: summarize_response\\nquestion: {question}\\nresponse: {response}\")\n",
    "    #     targets.append(explanation)\n",
    "\n",
    "print(f\"Generated {len(inputs)} total training pairs from {len(data)} records.\")\n",
    "train_inputs, val_inputs, train_targets, val_targets = train_test_split(\n",
    "    inputs, targets, test_size=0.1, random_state=42\n",
    ")\n",
    "print(f\"Train size: {len(train_inputs)} | Validation size: {len(val_inputs)}\")\n",
    "\n",
    "# Save splits\n",
    "train_data = [\n",
    "    {\"input_text\": inp, \"target_text\": tgt}\n",
    "    for inp, tgt in zip(train_inputs, train_targets)\n",
    "]\n",
    "val_data = [\n",
    "    {\"input_text\": inp, \"target_text\": tgt} for inp, tgt in zip(val_inputs, val_targets)\n",
    "]\n",
    "with open(\"train_data_2April.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(train_data, f, ensure_ascii=False, indent=2)\n",
    "with open(\"val_data_2April.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(val_data, f, ensure_ascii=False, indent=2)\n",
    "print(\"Saved train_data_2April.json and val_data_2April.json!\")\n",
    "\n",
    "# Build datasets\n",
    "raw_datasets = DatasetDict(\n",
    "    {\n",
    "        \"train\": Dataset.from_dict(\n",
    "            {\"input_text\": train_inputs, \"target_text\": train_targets}\n",
    "        ),\n",
    "        \"validation\": Dataset.from_dict(\n",
    "            {\"input_text\": val_inputs, \"target_text\": val_targets}\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "print(\"Train sample:\", raw_datasets[\"train\"][3])\n",
    "print(\"Validation sample:\", raw_datasets[\"validation\"][3])\n",
    "\n",
    "# 2. LOAD MODEL & TOKENIZER\n",
    "model_name = \"t5-base\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Add custom tokens once\n",
    "# custom_tokens = []\n",
    "# with open(\"all_relations_and_classes.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     custom_tokens.extend([line.strip() for line in f.readlines()])\n",
    "# with open(\"output_entities.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     custom_tokens.extend([line.strip() for line in f.readlines()])\n",
    "# num_added_tokens = tokenizer.add_tokens(custom_tokens)\n",
    "# model.resize_token_embeddings(len(tokenizer))\n",
    "# print(f\"Added {num_added_tokens} new tokens to the tokenizer!\")\n",
    "\n",
    "\n",
    "# 3. PREPROCESSING\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"input_text\"], max_length=512, truncation=True, padding=\"max_length\"\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        text_target=examples[\"target_text\"],\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "# 4. EVALUATION METRICS\n",
    "metric_rouge = evaluate.load(\"rouge\")\n",
    "metric_bleu = evaluate.load(\"bleu\")\n",
    "metric_meteor = evaluate.load(\"meteor\")\n",
    "metric_bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [label.strip() for label in decoded_labels]\n",
    "\n",
    "    results = {}\n",
    "    rouge_result = metric_rouge.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "    results.update(rouge_result)\n",
    "    bleu_result = metric_bleu.compute(\n",
    "        predictions=decoded_preds, references=[[label] for label in decoded_labels]\n",
    "    )\n",
    "    results[\"bleu\"] = bleu_result[\"bleu\"]\n",
    "    meteor_result = metric_meteor.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels\n",
    "    )\n",
    "    results[\"meteor\"] = meteor_result[\"meteor\"]\n",
    "    bertscore_result = metric_bertscore.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, lang=\"en\"\n",
    "    )\n",
    "    results[\"bertscore_precision\"] = np.mean(bertscore_result[\"precision\"])\n",
    "    results[\"bertscore_recall\"] = np.mean(bertscore_result[\"recall\"])\n",
    "    results[\"bertscore_f1\"] = np.mean(bertscore_result[\"f1\"])\n",
    "    prediction_lens = [\n",
    "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n",
    "    ]\n",
    "    results[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    return results\n",
    "\n",
    "\n",
    "# 5. TRAINING ARGUMENTS\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./training_t5small\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"rougeL\",\n",
    "    greater_is_better=True,\n",
    "    logging_strategy=\"epoch\",\n",
    "    logging_dir=\"./training_t5small\",\n",
    "    logging_steps=100,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,  # Adjust based on GPU\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=30,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,  # Enable if GPU supports\n",
    "    report_to=[\"tensorboard\"],\n",
    "    warmup_steps=500,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    ")\n",
    "\n",
    "# 6. TRAINER SETUP\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")\n",
    "\n",
    "# 7. TRAIN\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 52599 records from updated_combined_output_with_entity.json\n",
      "Example record: {'question': 'What is the area of building bldg1?', 'entity': 'brick:area', 'sparql': 'SELECT ?value ?unit WHERE { bldg:bldg1 brick:area ?area . ?area brick:value ?value . ?area brick:hasUnits ?unit . }', 'sparql_response': '[{\"value\": \"9973^^xsd:integer\", \"unit\": \"FT_2\"}]', 'explanation': 'The area of building bldg1 is 9,973 square feet (FT_2). This means that the total floor space occupied by this building is approximately 9,973 square feet. This measurement is commonly used for real estate and construction purposes to describe the size of a building or space. In this case, the number \"9,973\" represents the precise area of building bldg1 as obtained from the smart building data created using Brickschema ontology. The \"FT_2\" notation signifies that the unit of measurement is square feet (foot squared).', 'id': 1}\n",
      "Generated 101897 total training pairs from 52599 records.\n",
      "Train size: 91707 | Validation size: 10190\n",
      "Saved train_data_2April.json and val_data_2April.json!\n",
      "Train sample: {'input_text': \"task: generate_sparql\\ninput: Does Radiant Ceiling Panel include the tag 'Ceiling'?\\nentitybrick:Radiant_Ceiling_Panel\", 'target_text': 'ASK WHERE { brick:Radiant_Ceiling_Panel brick:hasAssociatedTag tag:Ceiling . }'}\n",
      "Validation sample: {'input_text': 'task: summarize_response\\nquestion: How is the Enthalpy Setpoint categorized in the ontology?\\nresponse: [{\"superclass\": \"Setpoint\"}]', 'target_text': \"The Enthalpy Setpoint, as categorized in the ontology created using BrickSchema, belongs to a broader class of terms called Setpoints. In building automation and control systems, a setpoint is a specific value or condition that an automated system aims to maintain for the optimal functioning of a particular component or system.\\n\\nIn this case, the Enthalpy Setpoint refers to the targeted enthalpy level in a controlled environment such as a building. Entalpy is a thermodynamic property that describes the total energy (heat and internal energy) of a substance per unit mass. By setting an enthalpy setpoint, the system can control the heating or cooling process more accurately and efficiently to maintain the desired indoor comfort conditions.\\n\\nOverall, understanding the Enthalpy Setpoint's classification as a Setpoint in this ontology helps build a comprehensive model for building automation systems by providing clarity on its role, significance, and interactions with other components within the smart building ecosystem.\"}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e0dc3bd3a5433d8e0798642432308f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/91707 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4125eb0c6674b368f5396359a27f93b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10190 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36562' max='343920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 36562/343920 1:53:29 < 15:54:07, 5.37 it/s, Epoch 3.19/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Meteor</th>\n",
       "      <th>Bertscore Precision</th>\n",
       "      <th>Bertscore Recall</th>\n",
       "      <th>Bertscore F1</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.295700</td>\n",
       "      <td>0.248385</td>\n",
       "      <td>0.504155</td>\n",
       "      <td>0.433181</td>\n",
       "      <td>0.496060</td>\n",
       "      <td>0.496050</td>\n",
       "      <td>0.005084</td>\n",
       "      <td>0.480016</td>\n",
       "      <td>0.934897</td>\n",
       "      <td>0.888933</td>\n",
       "      <td>0.910661</td>\n",
       "      <td>18.019725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.294300</td>\n",
       "      <td>0.248268</td>\n",
       "      <td>0.507756</td>\n",
       "      <td>0.438752</td>\n",
       "      <td>0.499885</td>\n",
       "      <td>0.499957</td>\n",
       "      <td>0.005157</td>\n",
       "      <td>0.482675</td>\n",
       "      <td>0.935279</td>\n",
       "      <td>0.889683</td>\n",
       "      <td>0.911232</td>\n",
       "      <td>18.021295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.293000</td>\n",
       "      <td>0.248041</td>\n",
       "      <td>0.511299</td>\n",
       "      <td>0.443744</td>\n",
       "      <td>0.503168</td>\n",
       "      <td>0.503253</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>0.484156</td>\n",
       "      <td>0.936100</td>\n",
       "      <td>0.890650</td>\n",
       "      <td>0.912128</td>\n",
       "      <td>18.020510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1259: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1259: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1259: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 181\u001b[0m\n\u001b[1;32m    169\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m    170\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    171\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[EarlyStoppingCallback(early_stopping_patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)]\n\u001b[1;32m    178\u001b[0m )\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# 7. TRAIN\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1939\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py:2279\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2279\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2282\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2283\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2284\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2285\u001b[0m ):\n\u001b[1;32m   2286\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2287\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/trainer.py:3349\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3347\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   3348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3349\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py:2242\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   2241\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2242\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m learning_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_lomo_optimizer:\n\u001b[1;32m   2244\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "def clear_cuda_cache():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"CUDA cache cleared and memory freed.\")\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"WANDB_MODE\"] = \"offline\"\n",
    "\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, EarlyStoppingCallback\n",
    "import gc\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "import evaluate\n",
    "import torch\n",
    "import nltk\n",
    "import numpy as np\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, DataCollatorForSeq2Seq\n",
    "\n",
    "# Set CUDA device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "\n",
    "# 1. LOAD AND PREPARE DATA\n",
    "DATA_FILE = \"updated_combined_output_with_entity.json\"\n",
    "with open(DATA_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "print(f\"Loaded {len(data)} records from {DATA_FILE}\")\n",
    "print(\"Example record:\", data[0])\n",
    "\n",
    "# Create multi-task training pairs\n",
    "inputs, targets = [], []\n",
    "for record in data:\n",
    "    question = record.get(\"question\", \"\")\n",
    "    entity = record.get(\"entity\", \"\")\n",
    "    sparql = record.get(\"sparql\", \"\")\n",
    "    response = record.get(\"sparql_response\", \"\")\n",
    "    explanation = record.get(\"explanation\", \"\")\n",
    "\n",
    "    # Task 1: NL to SPARQL\n",
    "    if question and entity and sparql:\n",
    "        inputs.append(f\"task: generate_sparql\\ninput: {question}\\nentity{entity}\")\n",
    "        targets.append(sparql)\n",
    "\n",
    "    # Task 2: Summarize response\n",
    "    if question and response and explanation:\n",
    "        inputs.append(\n",
    "            f\"task: summarize_response\\nquestion: {question}\\nresponse: {response}\"\n",
    "        )\n",
    "        targets.append(explanation)\n",
    "\n",
    "print(f\"Generated {len(inputs)} total training pairs from {len(data)} records.\")\n",
    "train_inputs, val_inputs, train_targets, val_targets = train_test_split(\n",
    "    inputs, targets, test_size=0.1, random_state=40\n",
    ")\n",
    "print(f\"Train size: {len(train_inputs)} | Validation size: {len(val_inputs)}\")\n",
    "\n",
    "# Save splits\n",
    "train_data = [\n",
    "    {\"input_text\": inp, \"target_text\": tgt}\n",
    "    for inp, tgt in zip(train_inputs, train_targets)\n",
    "]\n",
    "val_data = [\n",
    "    {\"input_text\": inp, \"target_text\": tgt} for inp, tgt in zip(val_inputs, val_targets)\n",
    "]\n",
    "with open(\"train_data_2April.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(train_data, f, ensure_ascii=False, indent=2)\n",
    "with open(\"val_data_2April.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(val_data, f, ensure_ascii=False, indent=2)\n",
    "print(\"Saved train_data_2April.json and val_data_2April.json!\")\n",
    "\n",
    "# Build datasets\n",
    "raw_datasets = DatasetDict(\n",
    "    {\n",
    "        \"train\": Dataset.from_dict(\n",
    "            {\"input_text\": train_inputs, \"target_text\": train_targets}\n",
    "        ),\n",
    "        \"validation\": Dataset.from_dict(\n",
    "            {\"input_text\": val_inputs, \"target_text\": val_targets}\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "print(\"Train sample:\", raw_datasets[\"train\"][3])\n",
    "print(\"Validation sample:\", raw_datasets[\"validation\"][3])\n",
    "\n",
    "# 2. LOAD MODEL & TOKENIZER\n",
    "model_name = \"./training_t5smallv2/checkpoint-343920\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Add custom tokens once\n",
    "# custom_tokens = []\n",
    "# with open(\"all_relations_and_classes.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     custom_tokens.extend([line.strip() for line in f.readlines()])\n",
    "# with open(\"output_entities.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     custom_tokens.extend([line.strip() for line in f.readlines()])\n",
    "# num_added_tokens = tokenizer.add_tokens(custom_tokens)\n",
    "# model.resize_token_embeddings(len(tokenizer))\n",
    "# print(f\"Added {num_added_tokens} new tokens to the tokenizer!\")\n",
    "\n",
    "\n",
    "# 3. PREPROCESSING\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"input_text\"], max_length=512, truncation=True, padding=\"max_length\"\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        text_target=examples[\"target_text\"],\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "# 4. EVALUATION METRICS\n",
    "metric_rouge = evaluate.load(\"rouge\")\n",
    "metric_bleu = evaluate.load(\"bleu\")\n",
    "metric_meteor = evaluate.load(\"meteor\")\n",
    "metric_bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [label.strip() for label in decoded_labels]\n",
    "\n",
    "    results = {}\n",
    "    rouge_result = metric_rouge.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "    results.update(rouge_result)\n",
    "    bleu_result = metric_bleu.compute(\n",
    "        predictions=decoded_preds, references=[[label] for label in decoded_labels]\n",
    "    )\n",
    "    results[\"bleu\"] = bleu_result[\"bleu\"]\n",
    "    meteor_result = metric_meteor.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels\n",
    "    )\n",
    "    results[\"meteor\"] = meteor_result[\"meteor\"]\n",
    "    bertscore_result = metric_bertscore.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, lang=\"en\"\n",
    "    )\n",
    "    results[\"bertscore_precision\"] = np.mean(bertscore_result[\"precision\"])\n",
    "    results[\"bertscore_recall\"] = np.mean(bertscore_result[\"recall\"])\n",
    "    results[\"bertscore_f1\"] = np.mean(bertscore_result[\"f1\"])\n",
    "    prediction_lens = [\n",
    "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n",
    "    ]\n",
    "    results[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    return results\n",
    "\n",
    "\n",
    "# 5. TRAINING ARGUMENTS\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./training_t5small\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"rougeL\",\n",
    "    greater_is_better=True,\n",
    "    logging_strategy=\"epoch\",\n",
    "    logging_dir=\"./training_t5small\",\n",
    "    logging_steps=100,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,  # Adjust based on GPU\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=30,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,  # Enable if GPU supports\n",
    "    report_to=[\"tensorboard\"],\n",
    "    warmup_steps=500,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    ")\n",
    "\n",
    "# 6. TRAINER SETUP\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")\n",
    "\n",
    "# 7. TRAIN\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda\n",
      "Loaded 10190 validation records from val_data_2April.json\n",
      "SPARQL task: 5187 examples\n",
      "Summarization task: 5003 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating SPARQL Generation Task ===\n",
      "Example 1:\n",
      "Input:      task: generate_sparql\n",
      "input: What types is the Occupied Heating Mode Status?\n",
      "entitybrick:Occupied_Heating_Mode_Status\n",
      "Prediction: SELECT?definition WHERE?quantity skos:definition?definition.\n",
      "Target:     SELECT ?type WHERE { brick:Occupied_Heating_Mode_Status a ?type . }\n",
      "--------------------------------------------------\n",
      "Example 2:\n",
      "Input:      task: generate_sparql\n",
      "input: Provide the definition for Air Flow Setpoint.\n",
      "entitybrick:Air_Flow_Setpoint\n",
      "Prediction: SELECT?definition WHERE brick:Fan skos:definition?definition.\n",
      "Target:     SELECT ?definition WHERE { brick:Air_Flow_Setpoint skos:definition ?definition . }\n",
      "--------------------------------------------------\n",
      "Example 3:\n",
      "Input:      task: generate_sparql\n",
      "input: Can you provide the definition for the Return Air Humidity Sensor?\n",
      "entitybrick:Return_Air_Humidity_Sensor\n",
      "Prediction: SELECT?definition WHERE?parent skos:definition?definition.\n",
      "Target:     SELECT ?definition WHERE { brick:Return_Air_Humidity_Sensor skos:definition ?definition . }\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f364a76bae4bb6acf7a1abecd9023d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "170d5df2438a4da8911004c94562b657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab189eb256a3422584e2e27e541cef07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07874690878040f6a84b4a997091386e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c990b85faca4133bf2b69d4655b416c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ad0627504c4d778b74cf3a5da5354a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SPARQL Generation Metrics:\n",
      "sparql_rouge_rouge1: 0.6714\n",
      "sparql_rouge_rouge2: 0.5177\n",
      "sparql_rouge_rougeL: 0.6709\n",
      "sparql_rouge_rougeLsum: 0.6709\n",
      "sparql_bleu: 0.3783\n",
      "sparql_meteor: 0.6631\n",
      "sparql_bertscore_precision: 0.9139\n",
      "sparql_bertscore_recall: 0.8740\n",
      "sparql_bertscore_f1: 0.8934\n",
      "sparql_gen_len: 3.8359\n",
      "\n",
      "=== Evaluating Summarization Task ===\n",
      "Example 1:\n",
      "Input:      task: summarize_response\n",
      "question: What is the quantity linked to the Return Air Enthalpy Sensor?\n",
      "response: [{\"quantity\": \"Enthalpy\"}]\n",
      "Prediction: The Return Air Enthalpy Sensor in this smart building system measures the enthalpy of the air being returned to the HVAC (Heating, Ventilation, and Air Conditioning) system. Enthalpy is a thermodynamic property that describes the total energy content of a substance (in this case, air) in a given volume of air. In simpler terms, the Return Air Enthalpy Sensor measures the enthalpy of the air being returned to the heating, ventilation, and air conditioning (HVAC) system after it has circulated through the space being conditioned. This information is crucial for maintaining optimal indoor air quality and energy efficiency within a smart building.\n",
      "Target:     The quantity linked to the Return Air Enthalpy Sensor is Enthalpy. In a building's HVAC (Heating, Ventilation, and Air Conditioning) system, enthalpy refers to the sum of the internal energy plus the product of pressure and specific volume for a given substance. This value can help determine the amount of heat energy that is contained within a certain mass of air or fluid, which is essential for maintaining comfortable temperatures in a building.\n",
      "\n",
      "In simpler terms, the Return Air Enthalpy Sensor measures the total heat content (combining internal energy and pressure) of the air being returned to the HVAC system. This information helps the HVAC system adjust itself accordingly, ensuring that appropriate cooling or heating is supplied as needed.\n",
      "--------------------------------------------------\n",
      "Example 2:\n",
      "Input:      task: summarize_response\n",
      "question: What is the name of Unoccupied Supply Air Flow Setpoint?\n",
      "response: [{\"label\": \"Unoccupied Supply Air Flow Setpoint\"}]\n",
      "Prediction: The term \"Unoccupied Supply Air Flow Setpoint\" refers to a specific setting in a smart building system. This setpoint is used to control the amount of air that should be supplied into an unoccupied space, such as a room or office. In simpler terms, it's the target amount of air that should be supplied into a space when no one is present in the building. This value is crucial for energy efficiency and comfort when the building is unoccupied.\n",
      "Target:     The Unoccupied Supply Air Flow Setpoint refers to a specific setting or target value for the amount of air that is supplied into a building when it's unoccupied. This value helps control the indoor environment and maintain comfortable conditions while saving energy by minimizing unnecessary heating, cooling, or ventilation. In other words, it's a predefined parameter for maintaining an optimal balance between energy efficiency and comfort levels when no one is using the space.\n",
      "--------------------------------------------------\n",
      "Example 3:\n",
      "Input:      task: summarize_response\n",
      "question: What is the equivalent class of Min Unoccupied Heating Supply Air Flow Setpoint Limit?\n",
      "response: [{\"equiv\": \"Min_Unoccupied_Heating_Discharge_Air_Flow_Setpoint_Limit\"}]\n",
      "Prediction: The Min Unoccupied Heating Supply Air Flow Setpoint Limit belongs to the class called \"Min_Unoccupied_Heating_Discharge_Air_Flow_Setpoint_Limit\". In simpler terms, this means that the Min Unoccupied Heating Supply Air Flow Setpoint Limit is a specific type or instance of the same class in the smart building ontology created using BrickSchema. The term \"Min_Unoccupied_Heating_Discharge_Air_Flow_Setpoint_Limit\" refers to the minimum amount of heated air that should be supplied when a space is unoccupied. This limit ensures that the heating system doesn't overheat when the space is unoccupied.\n",
      "Target:     The Min Unoccupied Heating Supply Air Flow Setpoint Limit belongs to the class named \"Min_Unoccupied_Heating_Discharge_Air_Flow_Setpoint_Limit\". This class represents a specific type of limit on the minimum amount of heated air flow that should be supplied when a building is unoccupied. It's an essential part of a smart building system, helping to optimize energy usage and maintain comfortable temperatures during periods of absence. The setpoint limit ensures that the heating system doesn't use more energy than necessary while the building is empty or minimally occupied.\n",
      "--------------------------------------------------\n",
      "\n",
      "Summarization Metrics:\n",
      "summarization_rouge_rouge1: 0.5542\n",
      "summarization_rouge_rouge2: 0.2751\n",
      "summarization_rouge_rougeL: 0.3622\n",
      "summarization_rouge_rougeLsum: 0.4157\n",
      "summarization_bleu: 0.1869\n",
      "summarization_meteor: 0.3544\n",
      "summarization_bertscore_precision: 0.9033\n",
      "summarization_bertscore_recall: 0.8834\n",
      "summarization_bertscore_f1: 0.8932\n",
      "summarization_gen_len: 108.3038\n",
      "CUDA cache cleared.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import T5ForConditionalGeneration\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    EarlyStoppingCallback,\n",
    "    T5Tokenizer,\n",
    "    DataCollatorForSeq2Seq,\n",
    ")\n",
    "import gc\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "import evaluate\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. LOAD THE FINE-TUNED MODEL AND TOKENIZER\n",
    "# -----------------------------------------------------------------------------\n",
    "model_name = \"./training_t5small/checkpoint-343920\"  # Use your latest checkpoint\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f\"Model loaded on {device}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. LOAD EVALUATION DATA\n",
    "# -----------------------------------------------------------------------------\n",
    "# Option 1: Load from validation split saved during training\n",
    "val_data_file = \"val_data_2April.json\"\n",
    "with open(val_data_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    val_data = json.load(f)\n",
    "print(f\"Loaded {len(val_data)} validation records from {val_data_file}\")\n",
    "\n",
    "# Separate tasks\n",
    "sparql_inputs = []\n",
    "sparql_targets = []\n",
    "summarization_inputs = []\n",
    "summarization_targets = []\n",
    "\n",
    "for record in val_data:\n",
    "    input_text = record[\"input_text\"]\n",
    "    target_text = record[\"target_text\"]\n",
    "\n",
    "    if \"task: generate_sparql\" in input_text:\n",
    "        sparql_inputs.append(input_text)\n",
    "        sparql_targets.append(target_text)\n",
    "    elif \"task: summarize_response\" in input_text:\n",
    "        summarization_inputs.append(input_text)\n",
    "        summarization_targets.append(target_text)\n",
    "\n",
    "print(f\"SPARQL task: {len(sparql_inputs)} examples\")\n",
    "print(f\"Summarization task: {len(summarization_inputs)} examples\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. DEFINE HELPER FUNCTIONS\n",
    "# -----------------------------------------------------------------------------\n",
    "def generate_predictions(input_texts, max_length=512):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for text in input_texts:\n",
    "            inputs = tokenizer(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                max_length=512,\n",
    "            ).to(device)\n",
    "            output_ids = model.generate(\n",
    "                inputs[\"input_ids\"],\n",
    "                max_length=max_length,\n",
    "                num_beams=4,  # Beam search for better quality\n",
    "                early_stopping=True,\n",
    "            )\n",
    "            pred = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "            predictions.append(pred.strip())\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4. LOAD EVALUATION METRICS\n",
    "# -----------------------------------------------------------------------------\n",
    "metric_rouge = evaluate.load(\"rouge\")\n",
    "metric_bleu = evaluate.load(\"bleu\")\n",
    "metric_meteor = evaluate.load(\"meteor\")\n",
    "metric_bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "\n",
    "def compute_metrics(predictions, references, task_name=\"\"):\n",
    "    results = {}\n",
    "    # ROUGE\n",
    "    rouge_result = metric_rouge.compute(\n",
    "        predictions=predictions, references=references, use_stemmer=True\n",
    "    )\n",
    "    results.update({f\"{task_name}_rouge_{k}\": v for k, v in rouge_result.items()})\n",
    "\n",
    "    # BLEU\n",
    "    bleu_result = metric_bleu.compute(\n",
    "        predictions=predictions, references=[[ref] for ref in references]\n",
    "    )\n",
    "    results[f\"{task_name}_bleu\"] = bleu_result[\"bleu\"]\n",
    "\n",
    "    # METEOR\n",
    "    meteor_result = metric_meteor.compute(\n",
    "        predictions=predictions, references=references\n",
    "    )\n",
    "    results[f\"{task_name}_meteor\"] = meteor_result[\"meteor\"]\n",
    "\n",
    "    # BERTScore\n",
    "    bertscore_result = metric_bertscore.compute(\n",
    "        predictions=predictions, references=references, lang=\"en\"\n",
    "    )\n",
    "    results[f\"{task_name}_bertscore_precision\"] = np.mean(bertscore_result[\"precision\"])\n",
    "    results[f\"{task_name}_bertscore_recall\"] = np.mean(bertscore_result[\"recall\"])\n",
    "    results[f\"{task_name}_bertscore_f1\"] = np.mean(bertscore_result[\"f1\"])\n",
    "\n",
    "    # Average generation length\n",
    "    prediction_lens = [len(pred.split()) for pred in predictions]\n",
    "    results[f\"{task_name}_gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5. EVALUATE SPARQL GENERATION TASK\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n=== Evaluating SPARQL Generation Task ===\")\n",
    "sparql_predictions = generate_predictions(sparql_inputs, max_length=128)\n",
    "\n",
    "# Print a few examples\n",
    "for i, (inp, pred, tgt) in enumerate(\n",
    "    zip(sparql_inputs[:3], sparql_predictions[:3], sparql_targets[:3])\n",
    "):\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(\"Input:     \", inp)\n",
    "    print(\"Prediction:\", pred)\n",
    "    print(\"Target:    \", tgt)\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Compute metrics\n",
    "sparql_metrics = compute_metrics(sparql_predictions, sparql_targets, task_name=\"sparql\")\n",
    "print(\"\\nSPARQL Generation Metrics:\")\n",
    "for k, v in sparql_metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6. EVALUATE SUMMARIZATION TASK\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n=== Evaluating Summarization Task ===\")\n",
    "summarization_predictions = generate_predictions(summarization_inputs, max_length=256)\n",
    "\n",
    "# Print a few examples\n",
    "for i, (inp, pred, tgt) in enumerate(\n",
    "    zip(\n",
    "        summarization_inputs[:3],\n",
    "        summarization_predictions[:3],\n",
    "        summarization_targets[:3],\n",
    "    )\n",
    "):\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(\"Input:     \", inp)\n",
    "    print(\"Prediction:\", pred)\n",
    "    print(\"Target:    \", tgt)\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Compute metrics\n",
    "summarization_metrics = compute_metrics(\n",
    "    summarization_predictions, summarization_targets, task_name=\"summarization\"\n",
    ")\n",
    "print(\"\\nSummarization Metrics:\")\n",
    "for k, v in summarization_metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 7. CLEAR CUDA CACHE (Optional)\n",
    "# -----------------------------------------------------------------------------\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"CUDA cache cleared.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test on new data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. LOAD THE TRAINED MODEL AND TOKENIZER\n",
    "# -----------------------------------------------------------------------------\n",
    "model_name = \"./training_t5small/checkpoint-57320\"  # Update with your checkpoint path\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f\"Model loaded on {device}\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. HELPER FUNCTION TO GENERATE RESPONSES\n",
    "# -----------------------------------------------------------------------------\n",
    "def generate_response(input_text, max_length=256):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(\n",
    "            input_text,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=512,\n",
    "        ).to(device)\n",
    "        output_ids = model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            max_length=max_length,\n",
    "            num_beams=4,  # Beam search for better quality\n",
    "            early_stopping=True,\n",
    "        )\n",
    "        response = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return response.strip()\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. INTERACTIVE TESTING LOOP\n",
    "# -----------------------------------------------------------------------------\n",
    "def test_model():\n",
    "    print(\"\\n=== Interactive Model Testing ===\")\n",
    "    print(\"Enter inputs for SPARQL generation or summarization tasks.\")\n",
    "    print(\n",
    "        \"For SPARQL: Provide a natural language question (e.g., 'What is the capital of France?')\"\n",
    "    )\n",
    "    print(\n",
    "        \"For Summarization: Provide a question and response (e.g., 'What is the weather like? [Weather data]')\"\n",
    "    )\n",
    "    print(\"Type 'exit' to quit.\\n\")\n",
    "\n",
    "    while True:\n",
    "        # Get user input\n",
    "        task_choice = input(\"Choose task (1 for SPARQL, 2 for Summarization): \").strip()\n",
    "\n",
    "        if task_choice.lower() == \"exit\":\n",
    "            break\n",
    "\n",
    "        if task_choice not in [\"1\", \"2\"]:\n",
    "            print(\"Invalid choice. Please enter 1 for SPARQL or 2 for Summarization.\")\n",
    "            continue\n",
    "\n",
    "        # Task 1: SPARQL Generation\n",
    "        if task_choice == \"1\":\n",
    "            question = input(\"Enter your question: \").strip()\n",
    "            if not question:\n",
    "                print(\"Please provide a question.\")\n",
    "                continue\n",
    "\n",
    "            # Add entity if provided (optional)\n",
    "            entity = input(\"Enter entity (optional, press Enter to skip): \").strip()\n",
    "            input_text = f\"task: generate_sparql\\ninput: {question}\"\n",
    "            if entity:\n",
    "                input_text += f\"\\nentity: {entity}\"\n",
    "\n",
    "            # Generate SPARQL\n",
    "            sparql_response = generate_response(input_text, max_length=128)\n",
    "            print(\"\\nGenerated SPARQL:\")\n",
    "            print(sparql_response)\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "        # Task 2: Summarization\n",
    "        elif task_choice == \"2\":\n",
    "            question = input(\"Enter your question: \").strip()\n",
    "            response = input(\"Enter the response to summarize: \").strip()\n",
    "            if not question or not response:\n",
    "                print(\"Please provide both a question and a response.\")\n",
    "                continue\n",
    "\n",
    "            input_text = (\n",
    "                f\"task: summarize_response\\nquestion: {question}\\nresponse: {response}\"\n",
    "            )\n",
    "\n",
    "            # Generate summary\n",
    "            summary_response = generate_response(input_text, max_length=256)\n",
    "            print(\"\\nGenerated Summary:\")\n",
    "            print(summary_response)\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4. RUN THE TEST\n",
    "# -----------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    test_model()\n",
    "\n",
    "    # Clear CUDA cache after testing (optional)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"CUDA cache cleared.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SPARQL Query:\n",
      "SELECT?definition WHERE brick:Heating_Ventilation_Air_Conditioning_System skos:definition?definition.\n",
      "\n",
      "Generated Summary:\n",
      "A Heating Ventilation Air Conditioning (HVAC) System refers to the collection of equipment, distribution systems, and terminals that provide, collectively or individually, the processes of heating, ventilating, or air conditioning to a specific building or portion of a building. This system is responsible for maintaining a comfortable indoor environment by regulating temperature, humidity, and air quality. The primary function of a HVAC system is to maintain a comfortable temperature for occupants while also ensuring energy efficiency.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Load your trained model and tokenizer from the saved directory.\n",
    "model_dir = \"./training_t5smallv2/checkpoint-343920\"  # Update this path if needed\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_dir)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_dir)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "def generate_sparql(question, entity):\n",
    "    \"\"\"\n",
    "    Generate a SPARQL query given a natural language question and an entity.\n",
    "    \"\"\"\n",
    "    # Format the input as it was during training.\n",
    "    input_text = f\"task: generate_sparql\\ninput: {question}\\nentity{entity}\"\n",
    "    input_ids = tokenizer.encode(\n",
    "        input_text, return_tensors=\"pt\", truncation=True, max_length=512\n",
    "    ).to(device)\n",
    "\n",
    "    # Generate output using beam search.\n",
    "    outputs = model.generate(\n",
    "        input_ids, max_length=150, num_beams=5, early_stopping=True\n",
    "    )\n",
    "    generated_sparql = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_sparql\n",
    "\n",
    "\n",
    "def summarize_response(question, response):\n",
    "    \"\"\"\n",
    "    Generate a summary (explanation) based on the question and response text.\n",
    "    \"\"\"\n",
    "    # Format the input as it was during training.\n",
    "    input_text = f\"task: summarize_response\\nquestion: {question}\\nresponse: {response}\"\n",
    "    input_ids = tokenizer.encode(\n",
    "        input_text, return_tensors=\"pt\", truncation=True, max_length=512\n",
    "    ).to(device)\n",
    "\n",
    "    # Generate summary output.\n",
    "    outputs = model.generate(\n",
    "        input_ids, max_length=256, num_beams=5, early_stopping=True\n",
    "    )\n",
    "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "\n",
    "# Example input data\n",
    "input_data = {\n",
    "    \"question\": \"Provide the definition for Heating Ventilation Air Conditioning System.\",\n",
    "    \"entity\": \"brick:Heating_Ventilation_Air_Conditioning_System\",\n",
    "    \"sparql\": \"SELECT ?definition WHERE { brick:Heating_Ventilation_Air_Conditioning_System skos:definition ?definition . }\",\n",
    "    \"sparql_response\": '[{\"definition\": \"The equipment, distribution systems and terminals that provide, either collectively or individually, the processes of heating, ventilating or air conditioning to a building or portion of a building\"}]',\n",
    "    \"explanation\": (\n",
    "        \"The Heating Ventilation Air Conditioning (HVAC) System is a set of equipment, systems, and components that work together \"\n",
    "        \"to control and maintain comfortable conditions within a building. This includes processes such as heating the interior space during \"\n",
    "        \"cold weather, cooling it during warm weather, moving air for ventilation, and maintaining the desired indoor air quality. The HVAC \"\n",
    "        \"system is crucial for providing a comfortable and healthy environment in any building, be it residential or commercial. It can \"\n",
    "        \"consist of various components like air handlers, ducts, vents, thermostats, boilers, furnaces, cooling towers, heat pumps, and more, \"\n",
    "        \"depending on the specific needs of the building. The HVAC system is designed to ensure that the temperature, humidity, and air quality \"\n",
    "        \"within the building are maintained at optimal levels for the comfort and health of its occupants.\"\n",
    "    ),\n",
    "    \"id\": 49568,\n",
    "}\n",
    "\n",
    "# Get outputs for both tasks\n",
    "sparql_output = generate_sparql(input_data[\"question\"], input_data[\"entity\"])\n",
    "summary_output = summarize_response(\n",
    "    input_data[\"question\"], input_data[\"sparql_response\"]\n",
    ")\n",
    "\n",
    "print(\"Generated SPARQL Query:\")\n",
    "print(sparql_output)\n",
    "print(\"\\nGenerated Summary:\")\n",
    "print(summary_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bldg_sensors_dash.txt\n"
     ]
    }
   ],
   "source": [
    "def add_prefix(input_file: str, output_file: str):\n",
    "    with open(input_file, \"r\") as infile, open(output_file, \"w\") as outfile:\n",
    "        for line in infile:\n",
    "            # Remove any trailing newline or whitespace\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                # Prepend \"bldg:\" to the line and write it to the output file\n",
    "                outfile.write(f\" - {line}\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    add_prefix(\"bldg_sensors.txt\", \"bldg_sensors_sufix.txt\")\n",
    "    print(\"bldg_sensors_dash.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continued Fine-Tuning: Combined Extended + Schema Datasets\n",
    "\n",
    "This section loads the two newly generated datasets:\n",
    "- `bldg3_dataset_extended.json` (semantic sensor + analytic queries)\n",
    "- `Transformers/t5_base/training/bldg3/bldg3_schema_dataset.json` (ontology/TBox + structural queries)\n",
    "\n",
    "It merges them into a single training corpus, converts multi-entity lists into a flat string for the model input, and continues fine-tuning from the latest prior checkpoint (if available) or the base `t5-base` model. New checkpoints will be written under `./trained/combined_t5/`.\n",
    "\n",
    "You can adjust hyperparameters (epochs, batch size, lr) in the following cells if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Dependencies installed and punkt tokenizer downloaded.\n"
     ]
    }
   ],
   "source": [
    "# Install / upgrade core dependencies (safe to re-run). Comment out versions to use latest.\n",
    "%pip install \\\n",
    "  transformers==4.44.2 \\\n",
    "  datasets==2.21.0 \\\n",
    "  evaluate==0.4.2 \\\n",
    "  accelerate==0.34.2 \\\n",
    "  sentencepiece==0.2.0 \\\n",
    "  nltk==3.9.1 \\\n",
    "  rouge-score==0.1.2 \\\n",
    "  bert-score==0.3.13 \\\n",
    "  sacrebleu==2.4.3 \\\n",
    "  scikit-learn==1.5.2 \\\n",
    "  pandas==2.2.2 \\\n",
    "  numpy==1.26.4 \\\n",
    "  torch --upgrade --quiet\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True)\n",
    "print('Dependencies installed and punkt tokenizer downloaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.8.0)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.11/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.11/dist-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.11/dist-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.11/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.11/dist-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.4.0->torch) (69.1.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (780.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.5/780.5 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (10.2.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.10.2.21->torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.7.3.90->torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==3.1.0 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sympy==1.13.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (2.1.5)\n",
      "Installing collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.4.0\n",
      "    Uninstalling triton-3.4.0:\n",
      "      Successfully uninstalled triton-3.4.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.14.0\n",
      "    Uninstalling sympy-1.14.0:\n",
      "      Successfully uninstalled sympy-1.14.0\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.8.90\n",
      "    Uninstalling nvidia-nvtx-cu12-12.8.90:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.8.90\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
      "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.8.90\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.8.90:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.90\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.93\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.93:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.93\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.8.90\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.8.90:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.90\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
      "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.8.0\n",
      "    Uninstalling torch-2.8.0:\n",
      "      Successfully uninstalled torch-2.8.0\n",
      "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.21.5 nvidia-nvtx-cu12-12.1.105 sympy-1.13.1 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121 triton-3.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.44.2)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.21.0)\n",
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.2)\n",
      "Requirement already satisfied: rouge-score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
      "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (2.4.3)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
      "Requirement already satisfied: bert-score in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.12.15)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (2.1.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/lib/python3/dist-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (3.2.0)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (6.0.2)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.3.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.5.1+cu121)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score) (3.8.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (1.1.10)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->bert-score) (12.8.93)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->bert-score) (2.4.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets evaluate rouge-score sacrebleu nltk bert-score scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping torch as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (780.5 MB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.3 MB)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.8.93)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (2.1.5)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall torch torchvision torchaudio -y\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: True\n",
      "GPU: NVIDIA RTX A6000\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import torch; print(f'CUDA: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \\\"None\\\"}')\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.20.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow<2.21,>=2.20 (from tf-keras)\n",
      "  Downloading tensorflow-2.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.6.3)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.5.4)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (16.0.6)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (23.2)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Downloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (69.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.62.1)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Downloading keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.26.4)\n",
      "Collecting h5py>=3.11.0 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Downloading h5py-3.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Downloading ml_dtypes-0.5.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras) (0.42.0)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.0.7)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras)\n",
      "  Downloading optree-0.17.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.5.2)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (10.2.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.2)\n",
      "Downloading tf_keras-2.20.1-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.20.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.6/620.6 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading h5py-3.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.11.3-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-6.32.1-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading optree-0.17.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (402 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.0/402.0 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: flatbuffers, protobuf, optree, ml_dtypes, h5py, tensorboard, keras, tensorflow, tf-keras\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 24.3.7\n",
      "    Uninstalling flatbuffers-24.3.7:\n",
      "      Successfully uninstalled flatbuffers-24.3.7\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.3\n",
      "    Uninstalling protobuf-4.25.3:\n",
      "      Successfully uninstalled protobuf-4.25.3\n",
      "  Attempting uninstall: ml_dtypes\n",
      "    Found existing installation: ml-dtypes 0.3.2\n",
      "    Uninstalling ml-dtypes-0.3.2:\n",
      "      Successfully uninstalled ml-dtypes-0.3.2\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.10.0\n",
      "    Uninstalling h5py-3.10.0:\n",
      "      Successfully uninstalled h5py-3.10.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.16.2\n",
      "    Uninstalling tensorboard-2.16.2:\n",
      "      Successfully uninstalled tensorboard-2.16.2\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.0.5\n",
      "    Uninstalling keras-3.0.5:\n",
      "      Successfully uninstalled keras-3.0.5\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.16.1\n",
      "    Uninstalling tensorflow-2.16.1:\n",
      "      Successfully uninstalled tensorflow-2.16.1\n",
      "Successfully installed flatbuffers-25.9.23 h5py-3.14.0 keras-3.11.3 ml_dtypes-0.5.3 optree-0.17.0 protobuf-6.32.1 tensorboard-2.20.0 tensorflow-2.20.0 tf-keras-2.20.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.22.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.3.0)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from wandb) (23.2)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.2.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (6.32.1)\n",
      "Collecting pydantic<3 (from wandb)\n",
      "  Downloading pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.5)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-2.39.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.10.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3->wandb)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3->wandb)\n",
      "  Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-extensions<5,>=4.8 (from wandb)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3->wandb)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading wandb-0.22.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading sentry_sdk-2.39.0-py2.py3-none-any.whl (370 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-extensions, smmap, sentry-sdk, annotated-types, typing-inspection, pydantic-core, gitdb, pydantic, gitpython, wandb\n",
      "\u001b[2K  Attempting uninstall: typing-extensions\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.10.0\n",
      "\u001b[2K    Uninstalling typing_extensions-4.10.0:\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.10.032m 0/10\u001b[0m [typing-extensions]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/10\u001b[0m [wandb]m 9/10\u001b[0m [wandb]ic]k]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 gitdb-4.0.12 gitpython-3.1.45 pydantic-2.11.9 pydantic-core-2.33.2 sentry-sdk-2.39.0 smmap-5.0.2 typing-extensions-4.15.0 typing-inspection-0.4.2 wandb-0.22.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc',\n",
       " 'wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sx wandb login 2eda0d96fb7751d51e6cf57d224d6f0792d83fec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msuhasdevmane\u001b[0m (\u001b[33msuhasdevmane-cardiff-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-04 12:09:55.512530: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-04 12:09:55.553414: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-04 12:09:56.603285: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B imported successfully.\n",
      "Loaded extended examples: 32573 | schema examples: 4423\n",
      "Total normalized records: 36996\n",
      "Prepared training pairs: 36996 (questions with SPARQL)\n",
      "Train size: 35146 | Validation size: 1850\n",
      "Saved merged_combined_corpus.json\n",
      "Continuing fine-tune from: ./trained/checkpoint-2\n",
      "Loaded tokenizer from ./trained/checkpoint-2\n",
      "Tokenizer vocabulary size: 32102\n",
      "Successfully loaded model from ./trained/checkpoint-2\n",
      "Model embedding size: 32102\n",
      "✓ Vocabulary sizes match: 32102\n",
      "\n",
      "============================================================\n",
      "DEVICE CONFIGURATION\n",
      "============================================================\n",
      "Using device: cuda\n",
      "GPU Device: NVIDIA RTX A6000\n",
      "GPU Memory Available: 47.40 GB\n",
      "CUDA Version: 12.1\n",
      "============================================================\n",
      "\n",
      "Model moved to cuda\n",
      "Using direct fallback implementation for 'rouge' metric\n",
      "Using direct fallback implementation for 'bleu' metric\n",
      "Using direct fallback implementation for 'meteor' metric\n",
      "Failed to load metric 'bertscore' from evaluate: Couldn't find a module script at /tf/notebooks/Transformers/T5_base/bertscore/bertscore.py. Module 'bertscore' doesn't exist on the Hugging Face Hub either.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load metric 'bertscore' after install attempt: Couldn't find a module script at /tf/notebooks/Transformers/T5_base/bertscore/bertscore.py. Module 'bertscore' doesn't exist on the Hugging Face Hub either.\n",
      "Using fallback implementation for 'bertscore'\n",
      "Metric loaders ready. Fallback usage:\n",
      "{'rouge_fallback': True, 'bleu_fallback': True, 'meteor_fallback': True, 'bertscore_fallback': True}\n",
      "Using tokenizer vocabulary size: 32102\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "507d31a7b8494ae1827202d3ce209eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35146 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f10b62778354ac4b007043818f6e25d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1850 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING CONFIGURATION\n",
      "============================================================\n",
      "Training on: cuda\n",
      "Mixed precision (FP16): True\n",
      "Batch size per device: 4\n",
      "Gradient accumulation steps: 4\n",
      "Effective batch size: 16\n",
      "Number of epochs: 5\n",
      "Learning rate: 0.0003\n",
      "Training samples: 35146\n",
      "Validation samples: 1850\n",
      "W&B Logging: Enabled\n",
      "W&B Run Name: T5-base-ft-20251004-121019\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msuhasdevmane\u001b[0m (\u001b[33msuhasdevmane-cardiff-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/notebooks/Transformers/T5_base/wandb/run-20251004_121020-gbfabcll</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/suhasdevmane-cardiff-university/huggingface/runs/gbfabcll' target=\"_blank\">T5-base-ft-20251004-121019</a></strong> to <a href='https://wandb.ai/suhasdevmane-cardiff-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/suhasdevmane-cardiff-university/huggingface' target=\"_blank\">https://wandb.ai/suhasdevmane-cardiff-university/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/suhasdevmane-cardiff-university/huggingface/runs/gbfabcll' target=\"_blank\">https://wandb.ai/suhasdevmane-cardiff-university/huggingface/runs/gbfabcll</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6897' max='10980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 6897/10980 2:35:32 < 1:32:06, 0.74 it/s, Epoch 3.14/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Meteor</th>\n",
       "      <th>Bertscore Precision</th>\n",
       "      <th>Bertscore Recall</th>\n",
       "      <th>Bertscore F1</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.999676</td>\n",
       "      <td>0.999459</td>\n",
       "      <td>0.999632</td>\n",
       "      <td>87.185665</td>\n",
       "      <td>0.831378</td>\n",
       "      <td>0.986361</td>\n",
       "      <td>0.973922</td>\n",
       "      <td>0.980094</td>\n",
       "      <td>75.247027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.001322</td>\n",
       "      <td>0.999676</td>\n",
       "      <td>0.999459</td>\n",
       "      <td>0.999632</td>\n",
       "      <td>87.185665</td>\n",
       "      <td>0.831378</td>\n",
       "      <td>0.986361</td>\n",
       "      <td>0.973922</td>\n",
       "      <td>0.980094</td>\n",
       "      <td>75.247027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "import os, json, random, math, gc, sys, time, statistics, traceback\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import (\n",
    "    T5Tokenizer, T5ForConditionalGeneration,\n",
    "    Seq2SeqTrainer, Seq2SeqTrainingArguments,\n",
    "    DataCollatorForSeq2Seq, EarlyStoppingCallback, TrainerCallback\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import evaluate\n",
    "\n",
    "# --- NEW: Import wandb for logging ---\n",
    "try:\n",
    "    import wandb\n",
    "    WANDB_AVAILABLE = True\n",
    "    print(\"W&B imported successfully.\")\n",
    "except ImportError:\n",
    "    WANDB_AVAILABLE = False\n",
    "    print(\"WARNING: wandb not installed. Install with 'pip install wandb' to enable online logging.\")\n",
    "# --------------------------------------\n",
    "\n",
    "\n",
    "SEED = 123\n",
    "random.seed(SEED)\n",
    "try:\n",
    "    import numpy as np\n",
    "    np.random.seed(SEED)\n",
    "except ImportError:\n",
    "    pass\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "EXTENDED_PATH = Path('./training/raw_merged_extended_datasets.json')\n",
    "SCHEMA_PATH = Path('./training/raw_merged_schema_datasets.json')\n",
    "assert EXTENDED_PATH.exists(), f\"Missing {EXTENDED_PATH}\"\n",
    "assert SCHEMA_PATH.exists(), f\"Missing {SCHEMA_PATH}\"\n",
    "\n",
    "with EXTENDED_PATH.open('r', encoding='utf-8') as f:\n",
    "    extended_data = json.load(f)\n",
    "with SCHEMA_PATH.open('r', encoding='utf-8') as f:\n",
    "    schema_data = json.load(f)\n",
    "\n",
    "print(f\"Loaded extended examples: {len(extended_data)} | schema examples: {len(schema_data)}\")\n",
    "\n",
    "def normalize(entry):\n",
    "    q = entry.get('question','').strip()\n",
    "    sparql = entry.get('sparql','').strip()\n",
    "    entities = entry.get('entities') or entry.get('entity') or []\n",
    "    if isinstance(entities, str):\n",
    "        entities_list = [e.strip() for e in entities.split('\\n') if e.strip()]\n",
    "    else:\n",
    "        entities_list = entities\n",
    "    entity_block = '\\n'.join(entities_list) if entities_list else ''\n",
    "    return {\n",
    "        'question': q,\n",
    "        'entities_list': entities_list,\n",
    "        'entity_block': entity_block,\n",
    "        'sparql': sparql\n",
    "    }\n",
    "\n",
    "normalized = [normalize(e) for e in extended_data] + [normalize(e) for e in schema_data]\n",
    "print(f\"Total normalized records: {len(normalized)}\")\n",
    "\n",
    "inputs, targets = [], []\n",
    "for rec in normalized:\n",
    "    if rec['question'] and rec['sparql']:\n",
    "        ent_part = f\"\\nentity: {rec['entity_block']}\" if rec['entity_block'] else ''\n",
    "        inputs.append(f\"task: generate_sparql\\ninput: {rec['question']}{ent_part}\")\n",
    "        targets.append(rec['sparql'])\n",
    "\n",
    "print(f\"Prepared training pairs: {len(inputs)} (questions with SPARQL)\")\n",
    "\n",
    "train_inputs, val_inputs, train_targets, val_targets = train_test_split(\n",
    "    inputs, targets, test_size=0.05, random_state=SEED\n",
    ")\n",
    "print(f\"Train size: {len(train_inputs)} | Validation size: {len(val_inputs)}\")\n",
    "\n",
    "raw_datasets = DatasetDict({\n",
    "    'train': Dataset.from_dict({'input_text': train_inputs, 'target_text': train_targets}),\n",
    "    'validation': Dataset.from_dict({'input_text': val_inputs, 'target_text': val_targets}),\n",
    "})\n",
    "\n",
    "with open('merged_combined_corpus.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump([\n",
    "        {'input_text': i, 'target_text': t} for i, t in zip(inputs, targets)\n",
    "    ], f, ensure_ascii=False, indent=2)\n",
    "print('Saved merged_combined_corpus.json')\n",
    "\n",
    "POSSIBLE_PREV = [\n",
    "    './trained/checkpoint-2',\n",
    "]\n",
    "model_source = None\n",
    "for path in POSSIBLE_PREV:\n",
    "    if Path(path).exists():\n",
    "        model_source = path\n",
    "        break\n",
    "if model_source is None:\n",
    "    model_source = 't5-base'\n",
    "print(f\"Continuing fine-tune from: {model_source}\")\n",
    "\n",
    "try:\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_source)\n",
    "    print(f\"Loaded tokenizer from {model_source}\")\n",
    "    print(f\"Tokenizer vocabulary size: {len(tokenizer)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Tokenizer load failed from {model_source}, falling back to t5-base: {e}\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "    print(f\"Tokenizer vocabulary size: {len(tokenizer)}\")\n",
    "\n",
    "try:\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_source, device_map=None)\n",
    "    print(f\"Successfully loaded model from {model_source}\")\n",
    "    print(f\"Model embedding size: {model.get_input_embeddings().weight.shape[0]}\")\n",
    "    if len(tokenizer) != model.get_input_embeddings().weight.shape[0]:\n",
    "        print(f\"WARNING: Vocabulary size mismatch!\")\n",
    "        print(f\"  Tokenizer vocab size: {len(tokenizer)}\")\n",
    "        print(f\"  Model embedding size: {model.get_input_embeddings().weight.shape[0]}\")\n",
    "        print(\"  This will cause IndexError during generation!\")\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        print(f\"✓ Vocabulary sizes match: {len(tokenizer)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Model load failed from {model_source}, falling back to t5-base: {e}\")\n",
    "    model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "    print(f\"Model embedding size: {model.get_input_embeddings().weight.shape[0]}\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\n{'='*60}\\nDEVICE CONFIGURATION\\n{'='*60}\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory Available: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU detected! Training will be very slow on CPU.\")\n",
    "    print(\"Make sure you have:\")\n",
    "    print(\"  1. A CUDA-capable GPU\")\n",
    "    print(\"  2. CUDA toolkit installed\")\n",
    "    print(\"  3. PyTorch with CUDA support:\")\n",
    "    print(\"      pip uninstall torch torchvision torchaudio -y\")\n",
    "    print(\"      pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    response = input(\"Continue with CPU training? (yes/no): \")\n",
    "    if response.lower() != 'yes':\n",
    "        print(\"Exiting. Please install CUDA support and try again.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "model.to(device)\n",
    "print(f\"Model moved to {device}\")\n",
    "\n",
    "# ----- T5 generation settings: prevents invalid pad tokens\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n",
    "model.config.decoder_start_token_id = tokenizer.pad_token_id\n",
    "if hasattr(model, \"generation_config\"):\n",
    "    model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "    model.generation_config.eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "SPECIAL_TOKENS = []\n",
    "if SPECIAL_TOKENS:\n",
    "    added = tokenizer.add_tokens([t for t in SPECIAL_TOKENS if t not in tokenizer.get_vocab()])\n",
    "    if added:\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "        print(f\"Added {added} special tokens\")\n",
    "\n",
    "def safe_load_metric(name, pip_pkg=None, alt=None):\n",
    "    if name in ['rouge', 'bleu', 'meteor'] and alt:\n",
    "        print(f\"Using direct fallback implementation for '{name}' metric\")\n",
    "        return alt, True\n",
    "    try:\n",
    "        metric = evaluate.load(name)\n",
    "        def _call(preds, refs):\n",
    "            return metric.compute(predictions=preds, references=refs)\n",
    "        return _call, False\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load metric '{name}' from evaluate: {e}\")\n",
    "        if pip_pkg:\n",
    "            try:\n",
    "                import subprocess\n",
    "                subprocess.run([sys.executable, '-m', 'pip', 'install', '--quiet', pip_pkg], check=False)\n",
    "                metric = evaluate.load(name)\n",
    "                def _call(preds, refs):\n",
    "                    return metric.compute(predictions=preds, references=refs)\n",
    "                return _call, False\n",
    "            except Exception as e2:\n",
    "                print(f\"Failed to load metric '{name}' after install attempt: {e2}\")\n",
    "        if alt:\n",
    "            print(f\"Using fallback implementation for '{name}'\")\n",
    "            return alt, True\n",
    "        else:\n",
    "            def _noop(preds, refs):\n",
    "                return {}\n",
    "            print(f\"No fallback available for metric '{name}'. Returning empty dict.\")\n",
    "            return _noop, True\n",
    "\n",
    "def rouge_fallback(preds, refs):\n",
    "    try:\n",
    "        from rouge_score import rouge_scorer\n",
    "    except ImportError:\n",
    "        import subprocess\n",
    "        subprocess.run([sys.executable, '-m', 'pip', 'install', '--quiet', 'rouge-score'], check=True)\n",
    "        from rouge_score import rouge_scorer\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1','rouge2','rougeL'], use_stemmer=True)\n",
    "    r1, r2, rl = [], [], []\n",
    "    for p, r in zip(preds, refs):\n",
    "        scores = scorer.score(r, p)\n",
    "        r1.append(scores['rouge1'].fmeasure)\n",
    "        r2.append(scores['rouge2'].fmeasure)\n",
    "        rl.append(scores['rougeL'].fmeasure)\n",
    "    return {\n",
    "        'rouge1': sum(r1)/len(r1) if r1 else 0.0,\n",
    "        'rouge2': sum(r2)/len(r2) if r2 else 0.0,\n",
    "        'rougeL': sum(rl)/len(rl) if rl else 0.0,\n",
    "    }\n",
    "\n",
    "def bleu_fallback(preds, refs):\n",
    "    try:\n",
    "        import sacrebleu\n",
    "    except ImportError:\n",
    "        import subprocess\n",
    "        subprocess.run([sys.executable, '-m', 'pip', 'install', '--quiet', 'sacrebleu'], check=True)\n",
    "        import sacrebleu\n",
    "    bleu = sacrebleu.corpus_bleu(preds, [refs])\n",
    "    return {'bleu': bleu.score}\n",
    "\n",
    "def meteor_fallback(preds, refs):\n",
    "    try:\n",
    "        import nltk\n",
    "        from nltk.translate.meteor_score import meteor_score\n",
    "    except ImportError:\n",
    "        import subprocess\n",
    "        subprocess.run([sys.executable, '-m', 'pip', 'install', '--quiet', 'nltk'], check=True)\n",
    "        import nltk\n",
    "        from nltk.translate.meteor_score import meteor_score\n",
    "    try:\n",
    "        nltk.data.find('corpora/wordnet')\n",
    "    except LookupError:\n",
    "        nltk.download('wordnet', quiet=True)\n",
    "    # Now split tokens for each sentence\n",
    "    scores = [meteor_score([r.split()], p.split()) for p, r in zip(preds, refs)]\n",
    "    return {'meteor': sum(scores)/len(scores) if scores else 0.0}\n",
    "\n",
    "def bertscore_fallback(preds, refs):\n",
    "    try:\n",
    "        from bert_score import score as bert_score\n",
    "    except ImportError:\n",
    "        import subprocess\n",
    "        subprocess.run([sys.executable, '-m', 'pip', 'install', '--quiet', 'bert-score'], check=False)\n",
    "        from bert_score import score as bert_score\n",
    "    P, R, F = bert_score(preds, refs, lang='en', verbose=False)\n",
    "    return {\n",
    "        'bertscore_precision': float(P.mean()),\n",
    "        'bertscore_recall': float(R.mean()),\n",
    "        'bertscore_f1': float(F.mean())\n",
    "    }\n",
    "\n",
    "metric_rouge, rouge_fallback_used = safe_load_metric('rouge', pip_pkg='rouge-score', alt=rouge_fallback)\n",
    "metric_bleu, bleu_fallback_used = safe_load_metric('bleu', pip_pkg='sacrebleu', alt=bleu_fallback)\n",
    "metric_meteor, meteor_fallback_used = safe_load_metric('meteor', pip_pkg='nltk', alt=meteor_fallback)\n",
    "metric_bertscore, bertscore_fallback_used = safe_load_metric('bertscore', pip_pkg='bert-score', alt=bertscore_fallback)\n",
    "\n",
    "print(\"Metric loaders ready. Fallback usage:\")\n",
    "print({\n",
    "    'rouge_fallback': rouge_fallback_used,\n",
    "    'bleu_fallback': bleu_fallback_used,\n",
    "    'meteor_fallback': meteor_fallback_used,\n",
    "    'bertscore_fallback': bertscore_fallback_used,\n",
    "})\n",
    "\n",
    "max_source_len = 512\n",
    "max_target_len = 256\n",
    "\n",
    "print(f\"Using tokenizer vocabulary size: {len(tokenizer)}\")\n",
    "label_pad_token_id = -100\n",
    "\n",
    "def preprocess(batch):\n",
    "    model_inputs = tokenizer(\n",
    "        batch['input_text'],\n",
    "        max_length=max_source_len,\n",
    "        truncation=True,\n",
    "        padding='max_length'\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        text_target=batch['target_text'],\n",
    "        max_length=max_target_len,\n",
    "        truncation=True,\n",
    "        padding='max_length'\n",
    "    )\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "tokenized = raw_datasets.map(preprocess, batched=True, remove_columns=['input_text','target_text'])\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, label_pad_token_id=label_pad_token_id)\n",
    "\n",
    "class MetricsTableCallback(TrainerCallback):\n",
    "    \"\"\"Custom callback to log metrics locally to a CSV file.\"\"\"\n",
    "    def __init__(self, save_csv_path='epoch_metrics_log.csv'):\n",
    "        self.save_csv_path = save_csv_path\n",
    "        self.rows = []\n",
    "    def on_evaluate(self, args, state, control, metrics, **kwargs):\n",
    "        # Hugging Face Trainer logs 'loss' and 'eval_loss'.\n",
    "        # Rename 'eval_loss' to 'validation_loss' for consistency with plotting script.\n",
    "        row = {\n",
    "            'epoch': state.epoch, # Add epoch for better CSV plotting\n",
    "            'step': state.global_step,\n",
    "            'training_loss': metrics.get('loss', 0.0),\n",
    "            'validation_loss': metrics.get('eval_loss', 0.0)\n",
    "        }\n",
    "        \n",
    "        # Add all computed metrics\n",
    "        for k,v in metrics.items():\n",
    "            if isinstance(v, (int, float)):\n",
    "                 # Only keep metrics not already captured and not starting with 'eval_'\n",
    "                if not k.startswith('eval_') and k not in ['loss']:\n",
    "                    row[k] = v\n",
    "                # Capture all eval metrics\n",
    "                elif k.startswith('eval_') and k != 'eval_loss':\n",
    "                    row[k.replace('eval_', '')] = v\n",
    "                    \n",
    "        self.rows.append(row)\n",
    "        return control\n",
    "        \n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        if self.rows:\n",
    "            try:\n",
    "                import csv\n",
    "                # Ensure 'epoch' and 'step' are first in the header\n",
    "                all_keys = {k for r in self.rows for k in r.keys()}\n",
    "                \n",
    "                # Define preferred order\n",
    "                keys_ordered = ['epoch', 'step', 'training_loss', 'validation_loss']\n",
    "                \n",
    "                # Append all other keys, sorted, ensuring no duplicates\n",
    "                remaining_keys = sorted(list(all_keys - set(keys_ordered)))\n",
    "                keys = keys_ordered + remaining_keys\n",
    "                \n",
    "                with open(self.save_csv_path, 'w', newline='', encoding='utf-8') as f:\n",
    "                    writer = csv.DictWriter(f, fieldnames=keys)\n",
    "                    writer.writeheader()\n",
    "                    for r in self.rows:\n",
    "                        # Ensure all rows have all keys for CSV\n",
    "                        writer.writerow({k: r.get(k, '') for k in keys}) \n",
    "                print(f\"Saved metrics log to {self.save_csv_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Could not save metrics CSV: {e}\")\n",
    "\n",
    "metrics_callback = MetricsTableCallback()\n",
    "\n",
    "# ----------- SAFE compute_metrics for T5 with decode patch -----------\n",
    "def compute_metrics(eval_pred):\n",
    "    import numpy as np\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    if isinstance(predictions, tuple):\n",
    "        predictions = predictions[0]\n",
    "\n",
    "    preds = np.asarray(predictions, dtype=np.int64)\n",
    "    labs = np.asarray(labels, dtype=np.int64)\n",
    "\n",
    "    invalid_pred_mask = (preds < 0) | (preds >= tokenizer.vocab_size)\n",
    "    if invalid_pred_mask.any():\n",
    "        preds[invalid_pred_mask] = tokenizer.pad_token_id\n",
    "\n",
    "    labs = np.where(labs == -100, tokenizer.pad_token_id, labs)\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labs, skip_special_tokens=True)\n",
    "    decoded_preds = [p.strip() for p in decoded_preds]\n",
    "    decoded_labels = [l.strip() for l in decoded_labels]\n",
    "    gen_lens = [len(tokenizer.encode(p)) for p in decoded_preds]\n",
    "    avg_len = sum(gen_lens)/len(gen_lens) if gen_lens else 0\n",
    "\n",
    "    rouge_res = metric_rouge(decoded_preds, decoded_labels)\n",
    "    bleu_res = metric_bleu(decoded_preds, decoded_labels)\n",
    "    meteor_res = metric_meteor(decoded_preds, decoded_labels)\n",
    "    bert_res = metric_bertscore(decoded_preds, decoded_labels)\n",
    "    metrics = {}\n",
    "    metrics.update({k: float(v) for k,v in rouge_res.items()})\n",
    "    metrics.update({k: float(v) for k,v in bleu_res.items()})\n",
    "    metrics.update({k: float(v) for k,v in meteor_res.items()})\n",
    "    metrics.update({k: float(v) for k,v in bert_res.items()})\n",
    "    metrics['gen_len'] = avg_len\n",
    "    \n",
    "    # Add prefix 'eval_' for all custom metrics to distinguish from training loss\n",
    "    # The Trainer automatically prefixes its loss metrics.\n",
    "    return {f\"eval_{k}\": v for k, v in metrics.items()}\n",
    "\n",
    "\n",
    "# --- UPDATED TRAINING ARGUMENTS FOR W&B ---\n",
    "# Define W&B specific settings\n",
    "WANDB_PROJECT_NAME = \"nl2sparql\"\n",
    "WANDB_RUN_NAME = f\"T5-base-ft-{time.strftime('%Y%m%d-%H%M%S')}\"\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./trained/checkpoint-4',\n",
    "    evaluation_strategy='epoch',\n",
    "    logging_strategy='steps',\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=3,\n",
    "    logging_steps=250,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=3e-4,\n",
    "    warmup_steps=200,\n",
    "    weight_decay=0.01,\n",
    "    predict_with_generate=True,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    generation_max_length=512,\n",
    "    generation_num_beams=1,\n",
    "    # --- W&B INTEGRATION START ---\n",
    "    report_to=[\"wandb\"] if WANDB_AVAILABLE else [\"none\"], # Tell the Trainer to use W&B\n",
    "    run_name=WANDB_RUN_NAME, # Name for the specific run on the dashboard\n",
    "    # Optional: set project name. If not set, it uses the WANDB_PROJECT environment variable.\n",
    "    # project_name=WANDB_PROJECT_NAME, \n",
    "    # --- W&B INTEGRATION END ---\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_rougeL', # Use 'eval_' prefix for the metric calculated in compute_metrics\n",
    "    greater_is_better=True,\n",
    "    seed=SEED,\n",
    "    dataloader_num_workers=2 if not sys.platform.startswith('win') else 0,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized['train'],\n",
    "    eval_dataset=tokenized['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3), metrics_callback]\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training on: {device}\")\n",
    "print(f\"Mixed precision (FP16): {training_args.fp16}\")\n",
    "print(f\"Batch size per device: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"Gradient accumulation steps: {training_args.gradient_accumulation_steps}\")\n",
    "print(f\"Effective batch size: {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\")\n",
    "print(f\"Number of epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"Learning rate: {training_args.learning_rate}\")\n",
    "print(f\"Training samples: {len(tokenized['train'])}\")\n",
    "print(f\"Validation samples: {len(tokenized['validation'])}\")\n",
    "print(f\"W&B Logging: {'Enabled' if WANDB_AVAILABLE else 'Disabled (install wandb)'}\")\n",
    "if WANDB_AVAILABLE:\n",
    "    print(f\"W&B Run Name: {WANDB_RUN_NAME}\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Initialize W&B manually if you want to set the project name or other config outside of Trainer args\n",
    "# Note: The Trainer handles wandb.init() automatically when report_to=\"wandb\" is set,\n",
    "# but if you need specific config, you can call it before trainer.train()\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Optional: end the W&B run manually when training is done\n",
    "if WANDB_AVAILABLE:\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try reduced learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-04 14:52:40.262357: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-04 14:52:40.303217: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-04 14:52:41.580165: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B imported successfully.\n",
      "Loaded extended examples: 32573 | schema examples: 4423\n",
      "Total normalized records: 36996\n",
      "Prepared training pairs: 36996 (questions with SPARQL)\n",
      "Train size: 35146 | Validation size: 1850\n",
      "Saved merged_combined_corpus.json with input text, target SPARQL, question, and entities.\n",
      "Continuing fine-tune from: ./trained/checkpoint-2\n",
      "Loaded tokenizer from ./trained/checkpoint-2\n",
      "Tokenizer vocabulary size: 32102\n",
      "Successfully loaded model from ./trained/checkpoint-2\n",
      "Model embedding size: 32102\n",
      "✓ Vocabulary sizes match: 32102\n",
      "\n",
      "============================================================\n",
      "DEVICE CONFIGURATION\n",
      "============================================================\n",
      "Using device: cuda\n",
      "GPU Device: NVIDIA RTX A6000\n",
      "GPU Memory Available: 47.40 GB\n",
      "CUDA Version: 12.1\n",
      "============================================================\n",
      "\n",
      "Model moved to cuda\n",
      "Using direct fallback implementation for 'rouge' metric\n",
      "Using direct fallback implementation for 'bleu' metric\n",
      "Using direct fallback implementation for 'meteor' metric\n",
      "Failed to load metric 'bertscore' from evaluate: Couldn't find a module script at /tf/notebooks/Transformers/T5_base/bertscore/bertscore.py. Module 'bertscore' doesn't exist on the Hugging Face Hub either.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load metric 'bertscore' after install attempt: Couldn't find a module script at /tf/notebooks/Transformers/T5_base/bertscore/bertscore.py. Module 'bertscore' doesn't exist on the Hugging Face Hub either.\n",
      "Using fallback implementation for 'bertscore'\n",
      "Metric loaders ready. Fallback usage:\n",
      "{'rouge_fallback': True, 'bleu_fallback': True, 'meteor_fallback': True, 'bertscore_fallback': True}\n",
      "Using tokenizer vocabulary size: 32102\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bada992d0ad74255b963f11831b0fb6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/35146 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25345e9bbacb405cabf9383b912903a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1850 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING CONFIGURATION\n",
      "============================================================\n",
      "Training on: cuda\n",
      "Mixed precision (FP16): True\n",
      "Batch size per device: 4\n",
      "Gradient accumulation steps: 4\n",
      "Effective batch size: 16\n",
      "Number of epochs: 5\n",
      "Learning rate: 0.0001\n",
      "Training samples: 35146\n",
      "Validation samples: 1850\n",
      "W&B Logging: Enabled\n",
      "W&B Run Name: T5-base-ft-20251004-145305\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msuhasdevmane\u001b[0m (\u001b[33msuhasdevmane-cardiff-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/tf/notebooks/Transformers/T5_base/wandb/run-20251004_145306-luni6xo6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/suhasdevmane-cardiff-university/huggingface/runs/luni6xo6' target=\"_blank\">T5-base-ft-20251004-145305</a></strong> to <a href='https://wandb.ai/suhasdevmane-cardiff-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/suhasdevmane-cardiff-university/huggingface' target=\"_blank\">https://wandb.ai/suhasdevmane-cardiff-university/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/suhasdevmane-cardiff-university/huggingface/runs/luni6xo6' target=\"_blank\">https://wandb.ai/suhasdevmane-cardiff-university/huggingface/runs/luni6xo6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10980' max='10980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10980/10980 3:02:26, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Meteor</th>\n",
       "      <th>Bertscore Precision</th>\n",
       "      <th>Bertscore Recall</th>\n",
       "      <th>Bertscore F1</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.999928</td>\n",
       "      <td>0.999884</td>\n",
       "      <td>0.999928</td>\n",
       "      <td>87.203594</td>\n",
       "      <td>0.831681</td>\n",
       "      <td>0.986410</td>\n",
       "      <td>0.973968</td>\n",
       "      <td>0.980142</td>\n",
       "      <td>75.257297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>87.205611</td>\n",
       "      <td>0.831723</td>\n",
       "      <td>0.986428</td>\n",
       "      <td>0.973974</td>\n",
       "      <td>0.980153</td>\n",
       "      <td>75.251892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>87.205611</td>\n",
       "      <td>0.831723</td>\n",
       "      <td>0.986428</td>\n",
       "      <td>0.973974</td>\n",
       "      <td>0.980153</td>\n",
       "      <td>75.251892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>87.205611</td>\n",
       "      <td>0.831723</td>\n",
       "      <td>0.986428</td>\n",
       "      <td>0.973974</td>\n",
       "      <td>0.980153</td>\n",
       "      <td>75.251892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
      "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
      "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved metrics log to epoch_metrics_log.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/bertscore_f1</td><td>▁████</td></tr><tr><td>eval/bertscore_precision</td><td>▁████</td></tr><tr><td>eval/bertscore_recall</td><td>▁████</td></tr><tr><td>eval/bleu</td><td>▁████</td></tr><tr><td>eval/gen_len</td><td>█▁▁▁▁</td></tr><tr><td>eval/loss</td><td>▁▇███</td></tr><tr><td>eval/meteor</td><td>▁████</td></tr><tr><td>eval/rouge1</td><td>▁████</td></tr><tr><td>eval/rouge2</td><td>▁████</td></tr><tr><td>eval/rougeL</td><td>▁████</td></tr><tr><td>+8</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/bertscore_f1</td><td>0.98015</td></tr><tr><td>eval/bertscore_precision</td><td>0.98643</td></tr><tr><td>eval/bertscore_recall</td><td>0.97397</td></tr><tr><td>eval/bleu</td><td>87.20561</td></tr><tr><td>eval/gen_len</td><td>75.25189</td></tr><tr><td>eval/loss</td><td>1e-05</td></tr><tr><td>eval/meteor</td><td>0.83172</td></tr><tr><td>eval/rouge1</td><td>0.99996</td></tr><tr><td>eval/rouge2</td><td>0.99996</td></tr><tr><td>eval/rougeL</td><td>0.99996</td></tr><tr><td>+13</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">T5-base-ft-20251004-145305</strong> at: <a href='https://wandb.ai/suhasdevmane-cardiff-university/huggingface/runs/luni6xo6' target=\"_blank\">https://wandb.ai/suhasdevmane-cardiff-university/huggingface/runs/luni6xo6</a><br> View project at: <a href='https://wandb.ai/suhasdevmane-cardiff-university/huggingface' target=\"_blank\">https://wandb.ai/suhasdevmane-cardiff-university/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251004_145306-luni6xo6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, json, random, math, gc, sys, time, statistics, traceback\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import (\n",
    "    T5Tokenizer, T5ForConditionalGeneration,\n",
    "    Seq2SeqTrainer, Seq2SeqTrainingArguments,\n",
    "    DataCollatorForSeq2Seq, EarlyStoppingCallback, TrainerCallback\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import evaluate\n",
    "\n",
    "# --- NEW: Import wandb for logging ---\n",
    "try:\n",
    "    import wandb\n",
    "    WANDB_AVAILABLE = True\n",
    "    print(\"W&B imported successfully.\")\n",
    "except ImportError:\n",
    "    WANDB_AVAILABLE = False\n",
    "    print(\"WARNING: wandb not installed. Install with 'pip install wandb' to enable online logging.\")\n",
    "# --------------------------------------\n",
    "\n",
    "\n",
    "SEED = 123\n",
    "random.seed(SEED)\n",
    "try:\n",
    "    import numpy as np\n",
    "    np.random.seed(SEED)\n",
    "except ImportError:\n",
    "    pass\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "EXTENDED_PATH = Path('./training/raw_merged_extended_datasets.json')\n",
    "SCHEMA_PATH = Path('./training/raw_merged_schema_datasets.json')\n",
    "assert EXTENDED_PATH.exists(), f\"Missing {EXTENDED_PATH}\"\n",
    "assert SCHEMA_PATH.exists(), f\"Missing {SCHEMA_PATH}\"\n",
    "\n",
    "with EXTENDED_PATH.open('r', encoding='utf-8') as f:\n",
    "    extended_data = json.load(f)\n",
    "with SCHEMA_PATH.open('r', encoding='utf-8') as f:\n",
    "    schema_data = json.load(f)\n",
    "\n",
    "print(f\"Loaded extended examples: {len(extended_data)} | schema examples: {len(schema_data)}\")\n",
    "\n",
    "def normalize(entry):\n",
    "    q = entry.get('question','').strip()\n",
    "    sparql = entry.get('sparql','').strip()\n",
    "    entities = entry.get('entities') or entry.get('entity') or []\n",
    "    if isinstance(entities, str):\n",
    "        entities_list = [e.strip() for e in entities.split('\\n') if e.strip()]\n",
    "    else:\n",
    "        entities_list = entities\n",
    "    entity_block = '\\n'.join(entities_list) if entities_list else ''\n",
    "    return {\n",
    "        'question': q,\n",
    "        'entities_list': entities_list,\n",
    "        'entity_block': entity_block,\n",
    "        'sparql': sparql\n",
    "    }\n",
    "\n",
    "normalized = [normalize(e) for e in extended_data] + [normalize(e) for e in schema_data]\n",
    "print(f\"Total normalized records: {len(normalized)}\")\n",
    "\n",
    "# --- UPDATED DATA PREPARATION TO SAVE ALL FIELDS ---\n",
    "inputs, targets = [], []\n",
    "corpus_records = [] # New list to hold records for the JSON dump\n",
    "for rec in normalized:\n",
    "    if rec['question'] and rec['sparql']:\n",
    "        ent_part = f\"\\nentity: {rec['entity_block']}\" if rec['entity_block'] else ''\n",
    "        \n",
    "        input_text = f\"task: generate_sparql\\ninput: {rec['question']}{ent_part}\"\n",
    "        target_text = rec['sparql']\n",
    "        \n",
    "        # Add to training lists\n",
    "        inputs.append(input_text)\n",
    "        targets.append(target_text)\n",
    "\n",
    "        # Add to corpus list for saving, including separate fields\n",
    "        corpus_records.append({\n",
    "            'input_text': input_text,\n",
    "            'target_text': target_text,\n",
    "            'question': rec['question'],\n",
    "            'entities_list': rec['entities_list'],\n",
    "            'entity_block': rec['entity_block'],\n",
    "        })\n",
    "# ---------------------------------------------------\n",
    "\n",
    "print(f\"Prepared training pairs: {len(inputs)} (questions with SPARQL)\")\n",
    "\n",
    "train_inputs, val_inputs, train_targets, val_targets = train_test_split(\n",
    "    inputs, targets, test_size=0.05, random_state=SEED\n",
    ")\n",
    "print(f\"Train size: {len(train_inputs)} | Validation size: {len(val_inputs)}\")\n",
    "\n",
    "raw_datasets = DatasetDict({\n",
    "    'train': Dataset.from_dict({'input_text': train_inputs, 'target_text': train_targets}),\n",
    "    'validation': Dataset.from_dict({'input_text': val_inputs, 'target_text': val_targets}),\n",
    "})\n",
    "\n",
    "# --- UPDATED JSON DUMPING ---\n",
    "with open('merged_combined_corpus.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(corpus_records, f, ensure_ascii=False, indent=2)\n",
    "print('Saved merged_combined_corpus.json with input text, target SPARQL, question, and entities.')\n",
    "# ----------------------------\n",
    "\n",
    "POSSIBLE_PREV = [\n",
    "    './trained/checkpoint-2',\n",
    "]\n",
    "model_source = None\n",
    "for path in POSSIBLE_PREV:\n",
    "    if Path(path).exists():\n",
    "        model_source = path\n",
    "        break\n",
    "if model_source is None:\n",
    "    model_source = 't5-base'\n",
    "print(f\"Continuing fine-tune from: {model_source}\")\n",
    "\n",
    "try:\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_source)\n",
    "    print(f\"Loaded tokenizer from {model_source}\")\n",
    "    print(f\"Tokenizer vocabulary size: {len(tokenizer)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Tokenizer load failed from {model_source}, falling back to t5-base: {e}\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "    print(f\"Tokenizer vocabulary size: {len(tokenizer)}\")\n",
    "\n",
    "try:\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_source, device_map=None)\n",
    "    print(f\"Successfully loaded model from {model_source}\")\n",
    "    print(f\"Model embedding size: {model.get_input_embeddings().weight.shape[0]}\")\n",
    "    if len(tokenizer) != model.get_input_embeddings().weight.shape[0]:\n",
    "        print(f\"WARNING: Vocabulary size mismatch!\")\n",
    "        print(f\"  Tokenizer vocab size: {len(tokenizer)}\")\n",
    "        print(f\"  Model embedding size: {model.get_input_embeddings().weight.shape[0]}\")\n",
    "        print(\"  This will cause IndexError during generation!\")\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        print(f\"✓ Vocabulary sizes match: {len(tokenizer)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Model load failed from {model_source}, falling back to t5-base: {e}\")\n",
    "    model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "    print(f\"Model embedding size: {model.get_input_embeddings().weight.shape[0]}\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\n{'='*60}\\nDEVICE CONFIGURATION\\n{'='*60}\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory Available: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU detected! Training will be very slow on CPU.\")\n",
    "    print(\"Make sure you have:\")\n",
    "    print(\"  1. A CUDA-capable GPU\")\n",
    "    print(\"  2. CUDA toolkit installed\")\n",
    "    print(\"  3. PyTorch with CUDA support:\")\n",
    "    print(\"      pip uninstall torch torchvision torchaudio -y\")\n",
    "    print(\"      pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    response = input(\"Continue with CPU training? (yes/no): \")\n",
    "    if response.lower() != 'yes':\n",
    "        print(\"Exiting. Please install CUDA support and try again.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "model.to(device)\n",
    "print(f\"Model moved to {device}\")\n",
    "\n",
    "# ----- T5 generation settings: prevents invalid pad tokens\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n",
    "model.config.decoder_start_token_id = tokenizer.pad_token_id\n",
    "if hasattr(model, \"generation_config\"):\n",
    "    model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "    model.generation_config.eos_token_id = tokenizer.eos_token_id\n",
    "\n",
    "SPECIAL_TOKENS = []\n",
    "if SPECIAL_TOKENS:\n",
    "    added = tokenizer.add_tokens([t for t in SPECIAL_TOKENS if t not in tokenizer.get_vocab()])\n",
    "    if added:\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "        print(f\"Added {added} special tokens\")\n",
    "\n",
    "def safe_load_metric(name, pip_pkg=None, alt=None):\n",
    "    if name in ['rouge', 'bleu', 'meteor'] and alt:\n",
    "        print(f\"Using direct fallback implementation for '{name}' metric\")\n",
    "        return alt, True\n",
    "    try:\n",
    "        metric = evaluate.load(name)\n",
    "        def _call(preds, refs):\n",
    "            return metric.compute(predictions=preds, references=refs)\n",
    "        return _call, False\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load metric '{name}' from evaluate: {e}\")\n",
    "        if pip_pkg:\n",
    "            try:\n",
    "                import subprocess\n",
    "                subprocess.run([sys.executable, '-m', 'pip', 'install', '--quiet', pip_pkg], check=False)\n",
    "                metric = evaluate.load(name)\n",
    "                def _call(preds, refs):\n",
    "                    return metric.compute(predictions=preds, references=refs)\n",
    "                return _call, False\n",
    "            except Exception as e2:\n",
    "                print(f\"Failed to load metric '{name}' after install attempt: {e2}\")\n",
    "        if alt:\n",
    "            print(f\"Using fallback implementation for '{name}'\")\n",
    "            return alt, True\n",
    "        else:\n",
    "            def _noop(preds, refs):\n",
    "                return {}\n",
    "            print(f\"No fallback available for metric '{name}'. Returning empty dict.\")\n",
    "            return _noop, True\n",
    "\n",
    "def rouge_fallback(preds, refs):\n",
    "    try:\n",
    "        from rouge_score import rouge_scorer\n",
    "    except ImportError:\n",
    "        import subprocess\n",
    "        subprocess.run([sys.executable, '-m', 'pip', 'install', '--quiet', 'rouge-score'], check=True)\n",
    "        from rouge_score import rouge_scorer\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1','rouge2','rougeL'], use_stemmer=True)\n",
    "    r1, r2, rl = [], [], []\n",
    "    for p, r in zip(preds, refs):\n",
    "        scores = scorer.score(r, p)\n",
    "        r1.append(scores['rouge1'].fmeasure)\n",
    "        r2.append(scores['rouge2'].fmeasure)\n",
    "        rl.append(scores['rougeL'].fmeasure)\n",
    "    return {\n",
    "        'rouge1': sum(r1)/len(r1) if r1 else 0.0,\n",
    "        'rouge2': sum(r2)/len(r2) if r2 else 0.0,\n",
    "        'rougeL': sum(rl)/len(rl) if rl else 0.0,\n",
    "    }\n",
    "\n",
    "def bleu_fallback(preds, refs):\n",
    "    try:\n",
    "        import sacrebleu\n",
    "    except ImportError:\n",
    "        import subprocess\n",
    "        subprocess.run([sys.executable, '-m', 'pip', 'install', '--quiet', 'sacrebleu'], check=True)\n",
    "        import sacrebleu\n",
    "    bleu = sacrebleu.corpus_bleu(preds, [refs])\n",
    "    return {'bleu': bleu.score}\n",
    "\n",
    "def meteor_fallback(preds, refs):\n",
    "    try:\n",
    "        import nltk\n",
    "        from nltk.translate.meteor_score import meteor_score\n",
    "    except ImportError:\n",
    "        import subprocess\n",
    "        subprocess.run([sys.executable, '-m', 'pip', 'install', '--quiet', 'nltk'], check=True)\n",
    "        import nltk\n",
    "        from nltk.translate.meteor_score import meteor_score\n",
    "    try:\n",
    "        nltk.data.find('corpora/wordnet')\n",
    "    except LookupError:\n",
    "        nltk.download('wordnet', quiet=True)\n",
    "    # Now split tokens for each sentence\n",
    "    scores = [meteor_score([r.split()], p.split()) for p, r in zip(preds, refs)]\n",
    "    return {'meteor': sum(scores)/len(scores) if scores else 0.0}\n",
    "\n",
    "def bertscore_fallback(preds, refs):\n",
    "    try:\n",
    "        from bert_score import score as bert_score\n",
    "    except ImportError:\n",
    "        import subprocess\n",
    "        subprocess.run([sys.executable, '-m', 'pip', 'install', '--quiet', 'bert-score'], check=False)\n",
    "        from bert_score import score as bert_score\n",
    "    P, R, F = bert_score(preds, refs, lang='en', verbose=False)\n",
    "    return {\n",
    "        'bertscore_precision': float(P.mean()),\n",
    "        'bertscore_recall': float(R.mean()),\n",
    "        'bertscore_f1': float(F.mean())\n",
    "    }\n",
    "\n",
    "metric_rouge, rouge_fallback_used = safe_load_metric('rouge', pip_pkg='rouge-score', alt=rouge_fallback)\n",
    "metric_bleu, bleu_fallback_used = safe_load_metric('bleu', pip_pkg='sacrebleu', alt=bleu_fallback)\n",
    "metric_meteor, meteor_fallback_used = safe_load_metric('meteor', pip_pkg='nltk', alt=meteor_fallback)\n",
    "metric_bertscore, bertscore_fallback_used = safe_load_metric('bertscore', pip_pkg='bert-score', alt=bertscore_fallback)\n",
    "\n",
    "print(\"Metric loaders ready. Fallback usage:\")\n",
    "print({\n",
    "    'rouge_fallback': rouge_fallback_used,\n",
    "    'bleu_fallback': bleu_fallback_used,\n",
    "    'meteor_fallback': meteor_fallback_used,\n",
    "    'bertscore_fallback': bertscore_fallback_used,\n",
    "})\n",
    "\n",
    "max_source_len = 512\n",
    "max_target_len = 256\n",
    "\n",
    "print(f\"Using tokenizer vocabulary size: {len(tokenizer)}\")\n",
    "label_pad_token_id = -100\n",
    "\n",
    "def preprocess(batch):\n",
    "    model_inputs = tokenizer(\n",
    "        batch['input_text'],\n",
    "        max_length=max_source_len,\n",
    "        truncation=True,\n",
    "        padding='max_length'\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        text_target=batch['target_text'],\n",
    "        max_length=max_target_len,\n",
    "        truncation=True,\n",
    "        padding='max_length'\n",
    "    )\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "tokenized = raw_datasets.map(preprocess, batched=True, remove_columns=['input_text','target_text'])\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, label_pad_token_id=label_pad_token_id)\n",
    "\n",
    "class MetricsTableCallback(TrainerCallback):\n",
    "    \"\"\"Custom callback to log metrics locally to a CSV file.\"\"\"\n",
    "    def __init__(self, save_csv_path='epoch_metrics_log.csv'):\n",
    "        self.save_csv_path = save_csv_path\n",
    "        self.rows = []\n",
    "    def on_evaluate(self, args, state, control, metrics, **kwargs):\n",
    "        # Hugging Face Trainer logs 'loss' and 'eval_loss'.\n",
    "        # Rename 'eval_loss' to 'validation_loss' for consistency with plotting script.\n",
    "        row = {\n",
    "            'epoch': state.epoch, # Add epoch for better CSV plotting\n",
    "            'step': state.global_step,\n",
    "            'training_loss': metrics.get('loss', 0.0),\n",
    "            'validation_loss': metrics.get('eval_loss', 0.0)\n",
    "        }\n",
    "        \n",
    "        # Add all computed metrics\n",
    "        for k,v in metrics.items():\n",
    "            if isinstance(v, (int, float)):\n",
    "                 # Only keep metrics not already captured and not starting with 'eval_'\n",
    "                if not k.startswith('eval_') and k not in ['loss']:\n",
    "                    row[k] = v\n",
    "                # Capture all eval metrics\n",
    "                elif k.startswith('eval_') and k != 'eval_loss':\n",
    "                    row[k.replace('eval_', '')] = v\n",
    "                    \n",
    "        self.rows.append(row)\n",
    "        return control\n",
    "        \n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        if self.rows:\n",
    "            try:\n",
    "                import csv\n",
    "                # Ensure 'epoch' and 'step' are first in the header\n",
    "                all_keys = {k for r in self.rows for k in r.keys()}\n",
    "                \n",
    "                # Define preferred order\n",
    "                keys_ordered = ['epoch', 'step', 'training_loss', 'validation_loss']\n",
    "                \n",
    "                # Append all other keys, sorted, ensuring no duplicates\n",
    "                remaining_keys = sorted(list(all_keys - set(keys_ordered)))\n",
    "                keys = keys_ordered + remaining_keys\n",
    "                \n",
    "                with open(self.save_csv_path, 'w', newline='', encoding='utf-8') as f:\n",
    "                    writer = csv.DictWriter(f, fieldnames=keys)\n",
    "                    writer.writeheader()\n",
    "                    for r in self.rows:\n",
    "                        # Ensure all rows have all keys for CSV\n",
    "                        writer.writerow({k: r.get(k, '') for k in keys}) \n",
    "                print(f\"Saved metrics log to {self.save_csv_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Could not save metrics CSV: {e}\")\n",
    "\n",
    "metrics_callback = MetricsTableCallback()\n",
    "\n",
    "# ----------- SAFE compute_metrics for T5 with decode patch -----------\n",
    "def compute_metrics(eval_pred):\n",
    "    import numpy as np\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    if isinstance(predictions, tuple):\n",
    "        predictions = predictions[0]\n",
    "\n",
    "    preds = np.asarray(predictions, dtype=np.int64)\n",
    "    labs = np.asarray(labels, dtype=np.int64)\n",
    "\n",
    "    invalid_pred_mask = (preds < 0) | (preds >= tokenizer.vocab_size)\n",
    "    if invalid_pred_mask.any():\n",
    "        preds[invalid_pred_mask] = tokenizer.pad_token_id\n",
    "\n",
    "    labs = np.where(labs == -100, tokenizer.pad_token_id, labs)\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labs, skip_special_tokens=True)\n",
    "    decoded_preds = [p.strip() for p in decoded_preds]\n",
    "    decoded_labels = [l.strip() for l in decoded_labels]\n",
    "    gen_lens = [len(tokenizer.encode(p)) for p in decoded_preds]\n",
    "    avg_len = sum(gen_lens)/len(gen_lens) if gen_lens else 0\n",
    "\n",
    "    rouge_res = metric_rouge(decoded_preds, decoded_labels)\n",
    "    bleu_res = metric_bleu(decoded_preds, decoded_labels)\n",
    "    meteor_res = metric_meteor(decoded_preds, decoded_labels)\n",
    "    bert_res = metric_bertscore(decoded_preds, decoded_labels)\n",
    "    metrics = {}\n",
    "    metrics.update({k: float(v) for k,v in rouge_res.items()})\n",
    "    metrics.update({k: float(v) for k,v in bleu_res.items()})\n",
    "    metrics.update({k: float(v) for k,v in meteor_res.items()})\n",
    "    metrics.update({k: float(v) for k,v in bert_res.items()})\n",
    "    metrics['gen_len'] = avg_len\n",
    "    \n",
    "    # Add prefix 'eval_' for all custom metrics to distinguish from training loss\n",
    "    # The Trainer automatically prefixes its loss metrics.\n",
    "    return {f\"eval_{k}\": v for k, v in metrics.items()}\n",
    "\n",
    "\n",
    "# --- UPDATED TRAINING ARGUMENTS FOR W&B ---\n",
    "# Define W&B specific settings\n",
    "WANDB_PROJECT_NAME = \"SPARQL-CodeGen-T5\"\n",
    "WANDB_RUN_NAME = f\"T5-base-ft-{time.strftime('%Y%m%d-%H%M%S')}\"\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./trained/checkpoint-5',\n",
    "    evaluation_strategy='epoch',\n",
    "    logging_strategy='steps',\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=3,\n",
    "    logging_steps=250,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=5,\n",
    "    # --- REDUCED LEARNING RATE FOR STABILITY ---\n",
    "    learning_rate=1e-4, \n",
    "    # ------------------------------------------\n",
    "    warmup_steps=200,\n",
    "    weight_decay=0.01,\n",
    "    predict_with_generate=True,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    generation_max_length=512,\n",
    "    generation_num_beams=1,\n",
    "    # --- W&B INTEGRATION START ---\n",
    "    report_to=[\"wandb\"] if WANDB_AVAILABLE else [\"none\"], # Tell the Trainer to use W&B\n",
    "    run_name=WANDB_RUN_NAME, # Name for the specific run on the dashboard\n",
    "    # Optional: set project name. If not set, it uses the WANDB_PROJECT environment variable.\n",
    "    # project_name=WANDB_PROJECT_NAME, \n",
    "    # --- W&B INTEGRATION END ---\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_rougeL', # Use 'eval_' prefix for the metric calculated in compute_metrics\n",
    "    greater_is_better=True,\n",
    "    seed=SEED,\n",
    "    dataloader_num_workers=2 if not sys.platform.startswith('win') else 0,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized['train'],\n",
    "    eval_dataset=tokenized['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3), metrics_callback]\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training on: {device}\")\n",
    "print(f\"Mixed precision (FP16): {training_args.fp16}\")\n",
    "print(f\"Batch size per device: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"Gradient accumulation steps: {training_args.gradient_accumulation_steps}\")\n",
    "print(f\"Effective batch size: {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\")\n",
    "print(f\"Number of epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"Learning rate: {training_args.learning_rate}\")\n",
    "print(f\"Training samples: {len(tokenized['train'])}\")\n",
    "print(f\"Validation samples: {len(tokenized['validation'])}\")\n",
    "print(f\"W&B Logging: {'Enabled' if WANDB_AVAILABLE else 'Disabled (install wandb)'}\")\n",
    "if WANDB_AVAILABLE:\n",
    "    print(f\"W&B Run Name: {WANDB_RUN_NAME}\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Initialize W&B manually if you want to set the project name or other config outside of Trainer args\n",
    "# Note: The Trainer handles wandb.init() automatically when report_to=\"wandb\" is set,\n",
    "# but if you need specific config, you can call it before trainer.train()\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Optional: end the W&B run manually when training is done\n",
    "if WANDB_AVAILABLE:\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# without wandb run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20396/957831681.py:185: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  bars = sns.barplot(x=list(sorted_scores.keys()), y=list(sorted_scores.values()),\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.signal import savgol_filter\n",
    "import os\n",
    "import math # Added for subplot calculation\n",
    "\n",
    "# Publication settings\n",
    "sns.set(style=\"whitegrid\")\n",
    "custom_palette = sns.color_palette(\"Set2\", 8)\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['figure.figsize'] = (9, 6)\n",
    "plt.rcParams['axes.facecolor'] = 'none'\n",
    "plt.rcParams['figure.facecolor'] = 'none'\n",
    "plt.rcParams['font.size'] = 16\n",
    "plt.rcParams['axes.labelsize'] = 19\n",
    "plt.rcParams['axes.titlesize'] = 22\n",
    "plt.rcParams['legend.fontsize'] = 17\n",
    "plt.rcParams['xtick.labelsize'] = 15\n",
    "plt.rcParams['ytick.labelsize'] = 15\n",
    "\n",
    "# Load CSV (Assuming this file exists in the execution environment)\n",
    "try:\n",
    "    df = pd.read_csv('epoch_metrics_log.csv')\n",
    "    df = df.fillna(0)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'epoch_metrics_log.csv' not found. Creating a dummy DataFrame.\")\n",
    "    # Create dummy data for demonstration if file is missing\n",
    "    data = {\n",
    "        'step': np.arange(1, 11) * 100,\n",
    "        'epoch': np.arange(1, 11),\n",
    "        'training_loss': np.linspace(2.0, 0.5, 10) + np.random.rand(10) * 0.1,\n",
    "        'validation_loss': np.linspace(2.5, 0.8, 10) + np.random.rand(10) * 0.1,\n",
    "        'ROUGE-1': np.linspace(0.2, 0.45, 10) + np.random.rand(10) * 0.05,\n",
    "        'ROUGE-2': np.linspace(0.05, 0.2, 10) + np.random.rand(10) * 0.03,\n",
    "        'ROUGE-L': np.linspace(0.15, 0.4, 10) + np.random.rand(10) * 0.05,\n",
    "        'BLEU': np.linspace(0.1, 0.35, 10) + np.random.rand(10) * 0.04,\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    df.iloc[7, df.columns.get_loc('validation_loss')] = 0.75 # Lower min val loss\n",
    "    df.iloc[8, df.columns.get_loc('ROUGE-L')] = 0.48 # Higher max metric\n",
    "    df = df.round(4)\n",
    "\n",
    "\n",
    "metrics = [col for col in df.columns if col not in ['step', 'epoch', 'training_loss', 'validation_loss']]\n",
    "score_metrics = [m for m in metrics if any(x in m.lower() for x in ['rouge', 'bleu', 'meteor', 'bert'])]\n",
    "\n",
    "# --- Loss Plot Function ---\n",
    "def plot_loss(df):\n",
    "    \"\"\"Plots training and validation loss curves, annotating minimums.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    if 'epoch' in df.columns and len(df['epoch'].unique()) > 1:\n",
    "        x = df['epoch']\n",
    "        x_label = 'Epoch'\n",
    "    elif 'step' in df.columns and len(df['step'].unique()) > 1:\n",
    "        x = df['step']\n",
    "        x_label = 'Step'\n",
    "    else:\n",
    "        x = np.arange(len(df))\n",
    "        x_label = 'Index'\n",
    "        \n",
    "    # Training Loss Plotting\n",
    "    if 'training_loss' in df and df['training_loss'].count() > 1:\n",
    "        ax.plot(x, df['training_loss'], color=custom_palette[0], marker='o', linestyle='-', label='Training Loss', markersize=6, alpha=0.7)\n",
    "        min_tr = df['training_loss'].min()\n",
    "        min_tr_idx = df['training_loss'].idxmin()\n",
    "        ax.annotate(f\"Min {min_tr:.3f}\", (x.iloc[min_tr_idx], min_tr),\n",
    "                    textcoords=\"offset points\", xytext=(0,-20), ha='center', fontsize=15, color=custom_palette[0],\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", alpha=0.6, ec=custom_palette[0]))\n",
    "        \n",
    "    # Validation Loss Plotting\n",
    "    if 'validation_loss' in df and df['validation_loss'].count() > 1:\n",
    "        ax.plot(x, df['validation_loss'], color=custom_palette[1], marker='s', linestyle='-', label='Validation Loss', markersize=6, alpha=0.7)\n",
    "        min_val = df['validation_loss'].min()\n",
    "        min_val_idx = df['validation_loss'].idxmin()\n",
    "        ax.annotate(f\"Min {min_val:.3f}\", (x.iloc[min_val_idx], min_val), \n",
    "                    textcoords=\"offset points\", xytext=(0,20), ha='center', fontsize=15, color=custom_palette[1],\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", alpha=0.6, ec=custom_palette[1]))\n",
    "\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_title('Training and Validation Loss Curves')\n",
    "    ax.legend(loc='best', frameon=True, shadow=True)\n",
    "    ax.grid(visible=True, which='major', linestyle='-', alpha=0.6)\n",
    "    ax.grid(visible=True, which='minor', linestyle='--', alpha=0.3)\n",
    "    ax.minorticks_on()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('loss_curves.png', transparent=True)\n",
    "    plt.savefig('loss_curves.pdf', transparent=True)\n",
    "    plt.close()\n",
    "\n",
    "# --- Metrics Plot Function (Improved Grouping) ---\n",
    "def plot_metrics(df, metrics):\n",
    "    \"\"\"Plots score metrics over epochs, grouping related metrics if necessary.\"\"\"\n",
    "    \n",
    "    # Simple strategy: Group ROUGE metrics, others go to a second group\n",
    "    rouge_metrics = sorted([m for m in metrics if 'rouge' in m.lower()])\n",
    "    other_metrics = sorted([m for m in metrics if m not in rouge_metrics])\n",
    "\n",
    "    metric_groups = []\n",
    "    if rouge_metrics:\n",
    "        metric_groups.append(('ROUGE Scores by Epoch', rouge_metrics))\n",
    "    if other_metrics:\n",
    "        metric_groups.append(('Other Scores by Epoch', other_metrics))\n",
    "\n",
    "    if not metric_groups:\n",
    "        print(\"No score metrics found to plot.\")\n",
    "        return\n",
    "\n",
    "    x = df['epoch'] if 'epoch' in df.columns else np.arange(len(df))\n",
    "    x_label = 'Epoch' if 'epoch' in df.columns else 'Index'\n",
    "\n",
    "    for plot_title, current_metrics in metric_groups:\n",
    "        if not current_metrics: continue\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(9, 6))\n",
    "        \n",
    "        for i, metric in enumerate(current_metrics):\n",
    "            if metric in df:\n",
    "                y = df[metric]\n",
    "                # Optionally smooth curves for >4 epochs/steps\n",
    "                y_smooth = y\n",
    "                if len(y) > 4:\n",
    "                    try:\n",
    "                        # Ensures window is odd and less than or equal to the length of data\n",
    "                        window = min(7, len(y) // 2 * 2 + 1 if len(y) % 2 == 0 else len(y))\n",
    "                        if window < 3: window = 3 # Minimum window length\n",
    "                        y_smooth = savgol_filter(y, window_length=window, polyorder=2)\n",
    "                    except Exception as e:\n",
    "                        # print(f\"Smoothing failed for {metric}: {e}\")\n",
    "                        y_smooth = y\n",
    "                        \n",
    "                color = custom_palette[i % len(custom_palette)]\n",
    "                ax.plot(x, y_smooth, label=metric, color=color, linewidth=2, linestyle='-')\n",
    "                \n",
    "                # Plot original data points (optional, for visibility)\n",
    "                # ax.plot(x, y, color=color, marker='o', linestyle='', alpha=0.4, markersize=5)\n",
    "\n",
    "                # Annotate best score on the original data for accuracy\n",
    "                best_val = y.max()\n",
    "                best_idx = y.idxmax()\n",
    "                \n",
    "                # Check for multiple max values and pick the latest one for annotation clarity\n",
    "                latest_best_idx = y[y == best_val].index[-1]\n",
    "                \n",
    "                ax.annotate(f\"Max {best_val:.3f}\", (x.iloc[latest_best_idx], y.iloc[latest_best_idx]), \n",
    "                            textcoords=\"offset points\", xytext=(0,10), ha='center', fontsize=14, color='black',\n",
    "                            bbox=dict(boxstyle=\"round,pad=0.2\", fc=color, alpha=0.3, ec=color))\n",
    "        \n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.set_ylabel('Score')\n",
    "        ax.set_title(plot_title)\n",
    "        ax.legend(loc='best', frameon=True, shadow=True)\n",
    "        ax.grid(visible=True, which='major', linestyle='-', alpha=0.6)\n",
    "        ax.grid(visible=True, which='minor', linestyle='--', alpha=0.3)\n",
    "        ax.minorticks_on()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        filename_base = plot_title.split(' ')[0].lower() # e.g., 'rouge' or 'other'\n",
    "        plt.savefig(f'{filename_base}_metrics_by_epoch.png', transparent=True)\n",
    "        plt.savefig(f'{filename_base}_metrics_by_epoch.pdf', transparent=True)\n",
    "        plt.close()\n",
    "\n",
    "# --- Best Scores Bar Plot Function ---\n",
    "def plot_best_scores(df, metrics):\n",
    "    \"\"\"Plots best metric scores from the epoch with minimum validation loss.\"\"\"\n",
    "    # Find the row corresponding to the minimum validation loss\n",
    "    best_idx = df['validation_loss'].idxmin() if 'validation_loss' in df.columns and df['validation_loss'].count() > 0 else df.index[-1]\n",
    "    best_row = df.iloc[best_idx]\n",
    "    \n",
    "    scores = {metric: best_row[metric] for metric in metrics if metric in best_row and pd.notna(best_row[metric])}\n",
    "    \n",
    "    if not scores:\n",
    "        print(\"No valid scores found for the best model to plot.\")\n",
    "        return\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    \n",
    "    # Sort scores alphabetically by metric name for consistent plotting\n",
    "    sorted_scores = dict(sorted(scores.items()))\n",
    "    \n",
    "    bars = sns.barplot(x=list(sorted_scores.keys()), y=list(sorted_scores.values()), \n",
    "                       palette=custom_palette, ax=ax, saturation=0.7)\n",
    "    \n",
    "    for bar, value in zip(bars.patches, sorted_scores.values()):\n",
    "        # Annotate values above the bars\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() * 1.01, \n",
    "                f'{value:.4f}', ha='center', va='bottom', fontsize=16, color='black')\n",
    "\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_xlabel('Metric')\n",
    "    ax.set_title(f'Performance Metrics at Epoch {best_row.get(\"epoch\", best_idx)}')\n",
    "    ax.set_ylim(0, max(scores.values()) * 1.1 + 0.05) # Better Y-axis scaling\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('best_score_barplot.png', transparent=True)\n",
    "    plt.savefig('best_score_barplot.pdf', transparent=True)\n",
    "    plt.close()\n",
    "\n",
    "# --- Summary Table Function ---\n",
    "def plot_summary_table(df, metrics):\n",
    "    \"\"\"Creates a visually styled summary table of the best metric scores.\"\"\"\n",
    "    # Find the row corresponding to the minimum validation loss\n",
    "    best_idx = df['validation_loss'].idxmin() if 'validation_loss' in df.columns and df['validation_loss'].count() > 0 else df.index[-1]\n",
    "    best_row = df.iloc[best_idx]\n",
    "    \n",
    "    cell_text = []\n",
    "    row_labels = []\n",
    "    \n",
    "    # Collect valid scores, sorted\n",
    "    valid_metrics = sorted([m for m in metrics if m in best_row and pd.notna(best_row[m])])\n",
    "    \n",
    "    for metric in valid_metrics:\n",
    "        score = best_row[metric]\n",
    "        cell_text.append([f\"{score:.4f}\"])\n",
    "        row_labels.append(metric)\n",
    "\n",
    "    if not row_labels:\n",
    "        print(\"No valid scores found for the summary table.\")\n",
    "        return\n",
    "\n",
    "    # Calculate figure size dynamically\n",
    "    fig_height = 1.5 + len(cell_text) * 0.4\n",
    "    fig_width = 6\n",
    "    fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "    \n",
    "    fig.patch.set_visible(False)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Create table\n",
    "    table = ax.table(cellText=cell_text, rowLabels=row_labels, colLabels=['Score'], \n",
    "                     loc='center', cellLoc='center', fontsize=17,\n",
    "                     cellColours=[['#f5f5f5']]*len(cell_text),\n",
    "                     colColours=[custom_palette[5]],\n",
    "                     rowColours=[custom_palette[6]]*len(cell_text))\n",
    "                     \n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(16)\n",
    "    table.scale(1.2, 1.5) # Scale slightly for better visibility\n",
    "    \n",
    "    plt.title('Best Model Performance Metrics', fontsize=20, y=0.95)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('metrics_summary_table.png', transparent=True)\n",
    "    plt.savefig('metrics_summary_table.pdf', transparent=True)\n",
    "    plt.close()\n",
    "\n",
    "# --- NEW: Combined Dashboard Plot Function ---\n",
    "def create_dashboard(df, metrics):\n",
    "    \"\"\"\n",
    "    Creates a multi-panel figure suitable for publication, combining\n",
    "    Loss Curves and key Metric Scores.\n",
    "    \"\"\"\n",
    "    if 'validation_loss' not in df.columns or df['validation_loss'].count() < 2 or not metrics:\n",
    "        print(\"Insufficient data for dashboard (need validation loss and score metrics).\")\n",
    "        return\n",
    "\n",
    "    # Determine which x-axis to use\n",
    "    if 'epoch' in df.columns and len(df['epoch'].unique()) > 1:\n",
    "        x = df['epoch']\n",
    "        x_label = 'Epoch'\n",
    "    elif 'step' in df.columns and len(df['step'].unique()) > 1:\n",
    "        x = df['step']\n",
    "        x_label = 'Step'\n",
    "    else:\n",
    "        x = np.arange(len(df))\n",
    "        x_label = 'Index'\n",
    "\n",
    "    # Setup the figure (1 row, 2 columns)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6)) # A wider figure\n",
    "    \n",
    "    # --- Panel 1: Loss Curves ---\n",
    "    ax1 = axes[0]\n",
    "    \n",
    "    # Training Loss\n",
    "    if 'training_loss' in df and df['training_loss'].count() > 1:\n",
    "        ax1.plot(x, df['training_loss'], color=custom_palette[0], linestyle='-', \n",
    "                 label='Training Loss', linewidth=2, alpha=0.7)\n",
    "        min_tr = df['training_loss'].min()\n",
    "        min_tr_idx = df['training_loss'].idxmin()\n",
    "        ax1.plot(x.iloc[min_tr_idx], min_tr, 'o', color=custom_palette[0], markersize=8)\n",
    "        \n",
    "    # Validation Loss\n",
    "    if 'validation_loss' in df and df['validation_loss'].count() > 1:\n",
    "        ax1.plot(x, df['validation_loss'], color=custom_palette[1], linestyle='-', \n",
    "                 label='Validation Loss', linewidth=2, alpha=0.9)\n",
    "        min_val = df['validation_loss'].min()\n",
    "        min_val_idx = df['validation_loss'].idxmin()\n",
    "        ax1.plot(x.iloc[min_val_idx], min_val, 's', color=custom_palette[1], markersize=8) # Square marker for min\n",
    "        \n",
    "    ax1.set_xlabel(x_label)\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('(a) Training and Validation Loss')\n",
    "    ax1.legend(loc='best', frameon=True)\n",
    "    ax1.grid(visible=True, which='major', linestyle='-', alpha=0.6)\n",
    "    ax1.minorticks_on()\n",
    "\n",
    "\n",
    "    # --- Panel 2: Metric Scores ---\n",
    "    ax2 = axes[1]\n",
    "    \n",
    "    # Prioritize ROUGE-L and/or BLEU as key metrics if they exist, otherwise use the first two\n",
    "    key_metrics = []\n",
    "    if 'ROUGE-L' in metrics: key_metrics.append('ROUGE-L')\n",
    "    if 'BLEU' in metrics and 'BLEU' not in key_metrics: key_metrics.append('BLEU')\n",
    "    if len(key_metrics) < 2 and metrics:\n",
    "        for m in metrics:\n",
    "            if m not in key_metrics:\n",
    "                key_metrics.append(m)\n",
    "                if len(key_metrics) == 2: break\n",
    "    \n",
    "    current_metrics = key_metrics # Only plot 2-3 key metrics in the dashboard for clarity\n",
    "    \n",
    "    for i, metric in enumerate(current_metrics):\n",
    "        if metric in df:\n",
    "            y = df[metric]\n",
    "            # Smooth the curve\n",
    "            y_smooth = y\n",
    "            if len(y) > 4:\n",
    "                try:\n",
    "                    window = min(7, len(y) // 2 * 2 + 1 if len(y) % 2 == 0 else len(y))\n",
    "                    if window < 3: window = 3\n",
    "                    y_smooth = savgol_filter(y, window_length=window, polyorder=2)\n",
    "                except Exception:\n",
    "                    y_smooth = y\n",
    "            \n",
    "            color = custom_palette[i % len(custom_palette) + 2] # Use different colors than loss\n",
    "            ax2.plot(x, y_smooth, label=metric, color=color, linewidth=2, linestyle='-')\n",
    "            \n",
    "            # Annotate best score\n",
    "            best_val = y.max()\n",
    "            best_idx = y.idxmax()\n",
    "            latest_best_idx = y[y == best_val].index[-1]\n",
    "            ax2.plot(x.iloc[latest_best_idx], y.iloc[latest_best_idx], 'D', color=color, markersize=8) # Diamond marker for max\n",
    "            \n",
    "    ax2.set_xlabel(x_label)\n",
    "    ax2.set_ylabel('Score')\n",
    "    ax2.set_title('(b) Key Evaluation Scores')\n",
    "    ax2.legend(loc='best', frameon=True)\n",
    "    ax2.grid(visible=True, which='major', linestyle='-', alpha=0.6)\n",
    "    ax2.minorticks_on()\n",
    "    \n",
    "    # Adjust overall layout\n",
    "    plt.suptitle('Model Performance Over Training', fontsize=24, y=1.02)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95]) # Make room for suptitle\n",
    "    plt.savefig('performance_dashboard.png', transparent=True)\n",
    "    plt.savefig('performance_dashboard.pdf', transparent=True)\n",
    "    plt.close()\n",
    "\n",
    "# --- Execution ---\n",
    "plot_loss(df)\n",
    "plot_metrics(df, score_metrics)\n",
    "plot_best_scores(df, score_metrics)\n",
    "plot_summary_table(df, score_metrics)\n",
    "create_dashboard(df, score_metrics)\n",
    "\n",
    "# print(\"Saved: loss_curves(.png/.pdf), [rouge/other]_metrics_by_epoch(.png/.pdf), best_score_barplot(.png/.pdf), metrics_summary_table(.png/.pdf), performance_dashboard(.png/.pdf)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOKE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sample 1 ---\n",
      "INPUT:\n",
      " task: generate_sparql\n",
      "input: What failure trends have been observed in  CO  Sensor 5.01's data over the last month?\n",
      "entity: bldg:CO_Level_Sensor_5.01\n",
      "TARGET:\n",
      " SELECT ?timeseriesId ?storedAt WHERE { bldg:CO_Level_Sensor_5.01 ref:hasExternalReference ?ref . ?ref a ref:TimeseriesReference ; ref:hasTimeseriesId ?timeseriesId ; ref:storedAt ?storedAt . }\n",
      "PRED:\n",
      " SELECT ?timeseriesId ?storedAt WHERE { bldg:CO_Level_Sensor_5.01 ref:hasExternalReference ?ref . ?ref a ref:TimeseriesReference ; ref:hasTimeseriesId ?timeseriesId ; ref:storedAt ?storedAt . }\n",
      "------------------------------------------------------------\n",
      "--- Sample 2 ---\n",
      "INPUT:\n",
      " task: generate_sparql\n",
      "input: What improvements can be made if Sensor 5.02's data deviates from our smart building standards?\n",
      "entity: bldg:Air_Quality_Sensor_5.02\n",
      "TARGET:\n",
      " SELECT ?timeseriesId ?storedAt WHERE { bldg:Air_Quality_Sensor_5.02 ref:hasExternalReference ?ref . ?ref a ref:TimeseriesReference ; ref:hasTimeseriesId ?timeseriesId ; ref:storedAt ?storedAt . }\n",
      "PRED:\n",
      " SELECT ?timeseriesId ?storedAt WHERE { bldg:Air_Quality_Sensor_5.02 ref:hasExternalReference ?ref . ?ref a ref:TimeseriesReference ; ref:hasTimeseriesId ?timeseriesId ; ref:storedAt ?storedAt . }\n",
      "------------------------------------------------------------\n",
      "--- Sample 3 ---\n",
      "INPUT:\n",
      " task: generate_sparql\n",
      "input: Provide the sensor type details for   Ethyl Alcohol /C2H5CH Sensor 5.02.\n",
      "entity: bldg:Ethyl_Alcohol_C2H5CH_Gas_Sensor_5.02\n",
      "TARGET:\n",
      " SELECT ?type WHERE { bldg:Ethyl_Alcohol_C2H5CH_Gas_Sensor_5.02 a ?type . }\n",
      "PRED:\n",
      " SELECT ?type WHERE { bldg:Ethyl_Alcohol_C2H5CH_Gas_Sensor_5.02 a ?type . }\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Quick smoke test on a couple of random samples after training (run after previous cell finishes)\n",
    "import random, json, torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from pathlib import Path\n",
    "\n",
    "model_dir = './trained/checkpoint-5/checkpoint-10980'\n",
    "if not Path(model_dir).exists():\n",
    "    print('Final model directory not found, please run the training cell first.')\n",
    "else:\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_dir)\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_dir)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    with open('merged_combined_corpus.json','r',encoding='utf-8') as f:\n",
    "        merged = json.load(f)\n",
    "\n",
    "    samples = random.sample(merged, k=min(3, len(merged)))\n",
    "    for i,s in enumerate(samples,1):\n",
    "        inp = s['input_text']\n",
    "        tgt = s['target_text']\n",
    "        inputs = tokenizer(inp, return_tensors='pt', truncation=True, padding='max_length', max_length=512).to(device)\n",
    "        out_ids = model.generate(inputs['input_ids'], max_length=256, num_beams=4)\n",
    "        pred = tokenizer.decode(out_ids[0], skip_special_tokens=True)\n",
    "        print(f'--- Sample {i} ---')\n",
    "        print('INPUT:\\n', inp[:400])\n",
    "        print('TARGET:\\n', tgt)\n",
    "        print('PRED:\\n', pred)\n",
    "        print('-'*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Fallback Explanation\n",
    "If `evaluate.load('rouge')` fails (e.g., offline environment, hub connectivity, or cache corruption), the previous cell now:\n",
    "\n",
    "- Tries to `pip install` a required package (e.g. `rouge-score`, `sacrebleu`, `nltk`, `bert-score`).\n",
    "- If that still fails, it uses a lightweight local fallback implementation for: ROUGE (rouge-score), BLEU (sacrebleu), METEOR (nltk), BERTScore (bert-score).\n",
    "- Prints which metrics are using fallbacks.\n",
    "\n",
    "Usage Notes:\n",
    "- To force re-download from Hugging Face Hub later, ensure network is available and re-run the cell.\n",
    "- If you want to skip a metric entirely, you can comment out its block in `compute_metrics`.\n",
    "- Starting training: uncomment `trainer.train()` at the bottom of the previous cell.\n",
    "\n",
    "Troubleshooting:\n",
    "- If BERTScore is slow on CPU, you can remove it or set a smaller batch by modifying the fallback.\n",
    "- For deterministic runs, set `seed` in `Seq2SeqTrainingArguments` and also `random.seed`, `numpy.random.seed`, `torch.manual_seed` before training.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
