# Quick start (PowerShell):
#   docker compose -f docker-compose.bldgX.yml -f docker-compose.extras.yml up -d --build
#   docker compose -f docker-compose.bldgX.yml -f docker-compose.extras.yml down
# Purpose: Optional extras overlay (nl2sparql, ollama, graphdb, jupyter, adminer) for any building stack.

# Optional extras that can be layered with any building stack using multiple -f flags.
# Example:
#   docker compose -f docker-compose.bldg1.yml -f docker-compose.extras.yml up -d --build

services:
  graphdb:
    image: devmanenvision/graphdb:10.4.2
    container_name: graphdb
    restart: always
    ports:
      - "7200:7200"
    volumes:
      - ./graphDB:/opt/graphdb/home/
    environment:
      - GRAPHDB_HOME=/opt/graphdb/home
      - GDB_USER=admin
      - GDB_PASSWORD=${GRAPHDB_PASSWORD:-change_me}
    networks:
      - ontobot-network

  jupyter:
    image: devmanenvision/jupyter_notebook:latest
    container_name: jupyter_notebook
    hostname: jupyter-notebook-host
    restart: always
    ports:
      - "8888:8888"
      - "8089:8089"
    volumes:
      - ./development/notebooks:/home/jovyan/work
      - ./rasa-bldg1/actions:/home/jovyan/work/rasa-actions
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - JUPYTER_TOKEN=${JUPYTER_TOKEN:-change_me}
    command:
      - start-notebook.sh
    networks:
      - ontobot-network

  adminer:
    image: devmanenvision/adminer:latest
    container_name: adminer
    hostname: adminerhost
    depends_on:
      - mysql
    ports:
      - 8282:8080
    networks:
      - ontobot-network

  nl2sparql:
    build:
      context: ./Transformers/t5_base/trained
    ports:
      - "6005:6005"
    volumes:
      - ./Transformers/t5_base/trained/checkpoint-2:/app/checkpoint-2:ro
    environment:
      - PYTHONUNBUFFERED=1
    container_name: nl2sparql_service
    hostname: nl2sparql-host
    restart: always
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:6005/health').read()"]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - ontobot-network

  ollama:
    container_name: ollama
    build:
      context: ./Transformers/Mistral
    pull_policy: always
    restart: unless-stopped
    ports:
      - "11434:11434"
    environment:
      - OLLAMA_NUM_PARALLEL=4
      - OLLAMA_MAX_LOADED_MODELS=2
      - OLLAMA_MODELS=/usr/share/ollama/.ollama/models
    healthcheck:
      test: "ollama --version && ollama ps || exit 1"
      interval: 30s
      timeout: 60s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    volumes:
      - ollama-models:/usr/share/ollama/.ollama/models
    networks:
      - ontobot-network

networks:
  ontobot-network:

volumes:
  ollama-models: